{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disdain.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qUdgslTobRO_",
        "yQVxLZXK-Qlu"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNxm34+WXfMNC9qgeWTr0m0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andythomasc/Text-Style-Transfer/blob/main/adversarial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbVl2Bf_-Loc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pd0SF4l-QAo"
      },
      "source": [
        "#TODOs\n",
        "###1. Write??? No. Modify files so that it's like them\n",
        "\n",
        "###2. Write and use load_dataset\n",
        "\n",
        "###3. Write and use training\n",
        "\n",
        "\n",
        "###4. Check, write and use the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg0YDUMr-QQG",
        "outputId": "39bdd4b4-8d56-42fc-da75-bff388ee2add"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3yxD5p4yqT3",
        "outputId": "5420dadb-d027-4fdd-d9d3-5a3c1058b764"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whi2m5WM-QZL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjdfNAub-Qfl",
        "outputId": "5895d8fa-f66a-4665-cd93-fc133caa4e12"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kleNfomx_qoc"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jyR97xT_qv2"
      },
      "source": [
        "import time\n",
        "import torchtext\n",
        "\n",
        "from torchtext.legacy import data\n",
        "import torch\n",
        "\n",
        "#from utils import tensor2text\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrVIDUAZd_Q5"
      },
      "source": [
        "from torch import nn, optim\n",
        "#from tensorboardX import SummaryWriter\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "#from evaluator import Evaluator\n",
        "#from utils import tensor2text, calc_ppl, idx2onehot, add_noise, word_drop\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUdgslTobRO_"
      },
      "source": [
        "#Utils\n",
        "\n",
        "Minimise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4tVrzZ_bTdj"
      },
      "source": [
        "def tensor2text(vocab, tensor):\n",
        "    tensor = tensor.cpu().numpy()\n",
        "    text = []\n",
        "    index2word = vocab.itos\n",
        "    eos_idx = vocab.stoi['<eos>']\n",
        "    unk_idx = vocab.stoi['<unk>']\n",
        "    stop_idxs = [vocab.stoi['!'], vocab.stoi['.'], vocab.stoi['?']]\n",
        "    for sample in tensor:\n",
        "        sample_filtered = []\n",
        "        prev_token = None\n",
        "        for idx in list(sample):\n",
        "            if prev_token in stop_idxs:\n",
        "                break\n",
        "            if idx == unk_idx or idx == prev_token or idx == eos_idx:\n",
        "                continue\n",
        "            prev_token = idx\n",
        "            sample_filtered.append(index2word[idx])\n",
        "            \n",
        "        sample = ' '.join(sample_filtered)\n",
        "        text.append(sample)\n",
        "\n",
        "    return text\n",
        "\n",
        "def calc_ppl(log_probs, tokens_mask):\n",
        "    return (log_probs.sum() / tokens_mask.sum()).exp()\n",
        "\n",
        "def idx2onehot(x, num_classes):\n",
        "    y = x.unsqueeze(-1)\n",
        "    x_onehot = torch.zeros_like(y.expand(x.size() + torch.Size((num_classes, ))))\n",
        "    x_onehot.scatter_(-1, y, 1)\n",
        "    return x_onehot.float()\n",
        "\n",
        "def word_shuffle(x, l, shuffle_len):\n",
        "    if not shuffle_len:\n",
        "        return x\n",
        "\n",
        "    noise = torch.rand(x.size(), dtype=torch.float).to(x.device)\n",
        "    pos_idx = torch.arange(x.size(1)).unsqueeze(0).expand_as(x).to(x.device)\n",
        "    pad_mask = (pos_idx >= l.unsqueeze(1)).float()\n",
        "\n",
        "    scores = pos_idx.float() + ((1 - pad_mask) * noise + pad_mask) * shuffle_len\n",
        "    x2 = x.clone()\n",
        "    x2 = x2.gather(1, scores.argsort(1))\n",
        "\n",
        "    return x2\n",
        "\n",
        "\n",
        "\n",
        "def word_dropout_raw(x, l, unk_drop_prob, rand_drop_prob, vocab):\n",
        "    if not unk_drop_prob and not rand_drop_prob:\n",
        "        return x\n",
        "\n",
        "    assert unk_drop_prob + rand_drop_prob <= 1\n",
        "\n",
        "    noise = torch.rand(x.size(), dtype=torch.float).to(x.device)\n",
        "    pos_idx = torch.arange(x.size(1)).unsqueeze(0).expand_as(x).to(x.device)\n",
        "    token_mask = pos_idx < l.unsqueeze(1)\n",
        "\n",
        "    x2 = x.clone()\n",
        "    \n",
        "    # drop to <unk> token\n",
        "    if unk_drop_prob:\n",
        "        unk_idx = vocab.stoi['<unk>']\n",
        "        unk_drop_mask = (noise < unk_drop_prob) & token_mask\n",
        "        x2.masked_fill_(unk_drop_mask, unk_idx)\n",
        "\n",
        "    # drop to random_mask\n",
        "    if rand_drop_prob:\n",
        "        rand_drop_mask = (noise > 1 - rand_drop_prob) & token_mask\n",
        "        rand_tokens = torch.randint_like(x, len(vocab))\n",
        "        rand_tokens.masked_fill_(1 - rand_drop_mask, 0)\n",
        "        x2.masked_fill_(rand_drop_mask, 0)\n",
        "        x2 = x2 + rand_tokens\n",
        "    \n",
        "    return x2\n",
        "\n",
        "def unk_dropout_(x, l, drop_prob, unk_idx):\n",
        "    noise = torch.rand(x.size(), dtype=torch.float).to(x.device)\n",
        "    pos_idx = torch.arange(x.size(1)).unsqueeze(0).expand_as(x).to(x.device)\n",
        "    token_mask = pos_idx < l.unsqueeze(1)\n",
        "    unk_drop_mask = (noise < drop_prob) & token_mask\n",
        "    x.masked_fill_(unk_drop_mask, unk_idx)\n",
        "\n",
        "def rand_dropout_(x, l, drop_prob, vocab_size):\n",
        "    noise = torch.rand(x.size(), dtype=torch.float).to(x.device)\n",
        "    pos_idx = torch.arange(x.size(1)).unsqueeze(0).expand_as(x).to(x.device)\n",
        "    token_mask = pos_idx < l.unsqueeze(1)\n",
        "    rand_drop_mask = (noise < drop_prob) & token_mask\n",
        "    rand_tokens = torch.randint_like(x, vocab_size)\n",
        "    rand_tokens.masked_fill_(1 - rand_drop_mask, 0)\n",
        "    x.masked_fill_(rand_drop_mask, 0)\n",
        "    x += rand_tokens\n",
        "\n",
        "def word_dropout_new(x, l, unk_drop_fac, rand_drop_fac, drop_prob, vocab):\n",
        "    if not unk_drop_fac and not rand_drop_fac:\n",
        "        return x\n",
        "\n",
        "    assert unk_drop_fac + rand_drop_fac <= 1\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    unk_idx = vocab.stoi['<unk>']\n",
        "    unk_drop_idx = int(batch_size * unk_drop_fac)\n",
        "    rand_drop_idx = int(batch_size * rand_drop_fac)\n",
        "\n",
        "    shuffle_idx = torch.argsort(torch.rand(batch_size))\n",
        "    orignal_idx = torch.argsort(shuffle_idx)\n",
        "\n",
        "    x2 = x.clone()\n",
        "    x2 = x2[shuffle_idx]\n",
        "    \n",
        "    if unk_drop_idx:\n",
        "        unk_dropout_(x2[:unk_drop_idx], l[:unk_drop_idx], drop_prob, unk_idx)\n",
        "\n",
        "    if rand_drop_idx:\n",
        "        rand_dropout_(x2[-rand_drop_idx:], l[-rand_drop_idx:], drop_prob, len(vocab))\n",
        "\n",
        "    x2 = x2[orignal_idx]\n",
        "\n",
        "    return x2\n",
        "\n",
        "def word_dropout(x, l, drop_prob, unk_idx):\n",
        "    if not drop_prob:\n",
        "        return x\n",
        "\n",
        "    noise = torch.rand(x.size(), dtype=torch.float).to(x.device)\n",
        "    pos_idx = torch.arange(x.size(1)).unsqueeze(0).expand_as(x).to(x.device)\n",
        "    token_mask = pos_idx < l.unsqueeze(1)\n",
        "\n",
        "    drop_mask = (noise < drop_prob) & token_mask\n",
        "    x2 = x.clone()\n",
        "    x2.masked_fill_(drop_mask, unk_idx)\n",
        "    \n",
        "    return x2\n",
        "\n",
        "def word_drop(x, l, drop_prob, pad_idx):\n",
        "    if not drop_prob:\n",
        "        return x\n",
        "\n",
        "    noise = torch.rand(x.size(), dtype=torch.float).to(x.device)\n",
        "    pos_idx = torch.arange(x.size(1)).unsqueeze(0).expand_as(x).to(x.device)\n",
        "    token_mask = pos_idx < (l.unsqueeze(1) - 1)\n",
        "\n",
        "    drop_mask = (noise < drop_prob) & token_mask\n",
        "    x2 = x.clone()\n",
        "    pos_idx.masked_fill_(drop_mask, x.size(1) - 1)\n",
        "    pos_idx = torch.sort(pos_idx, 1)[0]\n",
        "    x2 = x2.gather(1, pos_idx)\n",
        "    \n",
        "    return x2\n",
        "\n",
        "def add_noise(words, lengths, shuffle_len, drop_prob, unk_idx):\n",
        "    words = word_shuffle(words, lengths, shuffle_len)\n",
        "    words = word_dropout(words, lengths, drop_prob, unk_idx)\n",
        "    return words "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESHnFjOc_qzs"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQVxLZXK-Qlu"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyBAsL3b_ygS"
      },
      "source": [
        "check the main as well??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHWQQI8DaxDe"
      },
      "source": [
        "class DatasetIterator(object):\n",
        "  def __init__(self, pos_iter, neg_iter):\n",
        "    self.pos_iter = pos_iter\n",
        "    self.neg_iter = neg_iter\n",
        "\n",
        "  def __iter__(self):\n",
        "    for batch_pos, batch_neg in zip(iter(self.pos_iter), iter(self.neg_iter)):\n",
        "      if batch_pos.text.size(0) == batch_neg.text.size(0):\n",
        "        yield batch_pos.text, batch_neg.text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG6Yndvcc-lv"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWJeVAk24CAU"
      },
      "source": [
        "#paths\n",
        "#train_pos_path = '/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/label_1.txt'\n",
        "#train_neg_path = '/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/label_0.txt'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCiFMsY_-Qqd"
      },
      "source": [
        "\n",
        "\n",
        "def load_dataset(config, train_pos='label_1.txt',train_neg='label_0.txt',\n",
        "                 dev_pos = 'label_1.txt', dev_neg = 'label_0.txt',\n",
        "                 test_pos = 'label_1.txt', test_neg = 'label_0.txt'):\n",
        "  \n",
        "  #Go the the root path and then make use of the parsed strings\n",
        "  #eg train.pos \n",
        "  root = config.data_path\n",
        "\n",
        "  #inspect this??\n",
        "  TEXT = data.Field(batch_first= True, eos_token='<eos>')\n",
        "\n",
        "\n",
        "##building dataset\n",
        "    #lambda function easy for map\n",
        "  dataset_fn = lambda name: data.TabularDataset(\n",
        "      path = root + name,\n",
        "      format = 'tsv',\n",
        "      fields = [('text', TEXT)]\n",
        "  )\n",
        "  train_pos_set, train_neg_set = map(dataset_fn, [train_pos, train_neg])  #train dataset\n",
        "  dev_pos_set, dev_neg_set = map(dataset_fn, [dev_pos, dev_neg])          #dev dataset\n",
        "  test_pos_set, test_neg_set = map(dataset_fn, [test_pos, test_neg])      #test dataset\n",
        "\n",
        "  #vocab part\n",
        "  TEXT.build_vocab(train_pos_set, train_neg_set, min_freq=config.min_freq)\n",
        "  \n",
        "  #using GloVe from stanford for pretrained embeddings\n",
        "  if config.load_pretrained_embed:\n",
        "    start = time.time()\n",
        "\n",
        "    vectors = torchtext.vocab.GloVe('6B',dim=config.embed_size, cache=config.pretrained_embed_path)\n",
        "    TEXT.vocab.set_vectors(vectors.stoi, vectors.vectors, vectors.dim)\n",
        "    print('vectors', TEXT.vocab.vectors.size())\n",
        "\n",
        "    print('load embedding took {:.2f} s.'.format(time.time() - start))\n",
        "\n",
        "\n",
        "  vocab = TEXT.vocab\n",
        "\n",
        "\n",
        "  dataiter_fn = lambda dataset, train: data.BucketIterator(\n",
        "      dataset = dataset,\n",
        "      batch_size = config.batch_size,\n",
        "      shuffle=train,\n",
        "      repeat=train,\n",
        "      sort_key = lambda x: len(x.test),\n",
        "      sort_within_batch=False,\n",
        "      device=config.device\n",
        "  )\n",
        "\n",
        "  train_pos_iter, train_neg_iter = map(lambda x: dataiter_fn(x, True), [train_pos_set, train_neg_set])\n",
        "  dev_pos_iter, dev_neg_iter = map(lambda x: dataiter_fn(x, False), [dev_pos_set, dev_neg_set])\n",
        "  test_pos_iter, test_neg_iter = map(lambda x: dataiter_fn(x, False), [test_pos_set,test_neg_set])\n",
        "\n",
        "  train_iters = DatasetIterator(train_pos_iter, train_neg_iter)\n",
        "  dev_iters = DatasetIterator(dev_pos_iter, dev_neg_iter)\n",
        "  test_iters = DatasetIterator(test_pos_iter, test_neg_iter)\n",
        "\n",
        "  return train_iters, dev_iters, test_iters, vocab\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q41Xhw_Zyzf"
      },
      "source": [
        "\n",
        "class Config():\n",
        "    data_path = '/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/'\n",
        "    log_dir = '/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/runs/exp'\n",
        "    save_path = '/content/drive/My Drive/Colab Notebooks/style_transfer/training_files//save'\n",
        "    pretrained_embed_path = '/content/drive/My Drive/Colab Notebooks/style_transfer/embedding/'\n",
        "    device = torch.device('cuda' if True and torch.cuda.is_available() else 'cpu')\n",
        "    discriminator_method = 'Multi' # 'Multi' or 'Cond'\n",
        "    load_pretrained_embed = False\n",
        "    min_freq = 3\n",
        "    max_length = 400  # modified from 16\n",
        "    embed_size = 256\n",
        "    d_model = 256\n",
        "    h = 4\n",
        "    num_styles = 2\n",
        "    num_classes = num_styles + 1 if discriminator_method == 'Multi' else 2\n",
        "    num_layers = 4\n",
        "    batch_size = 1#10\n",
        "    lr_F = 0.0001\n",
        "    lr_D = 0.0001\n",
        "    L2 = 0\n",
        "    iter_D = 10\n",
        "    iter_F = 5\n",
        "    F_pretrain_iter = 10#500\n",
        "    log_steps = 5\n",
        "    eval_steps = 25\n",
        "    learned_pos_embed = True\n",
        "    dropout = 0\n",
        "    drop_rate_config = [(1, 0)]\n",
        "    temperature_config = [(1, 0)]\n",
        "\n",
        "    slf_factor = 0.25\n",
        "    cyc_factor = 0.5\n",
        "    adv_factor = 1\n",
        "\n",
        "    inp_shuffle_len = 0\n",
        "    inp_unk_drop_fac = 0\n",
        "    inp_rand_drop_fac = 0\n",
        "    inp_drop_prob = 0\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jscCd8Go6raD"
      },
      "source": [
        "config = Config()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11RK1pdla_4-"
      },
      "source": [
        "#train_iters, dev_iters, test_iters, vocab = load_dataset(config)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Mh0CFrcm99"
      },
      "source": [
        "#train_iters"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3mSvpwVkEvM"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgIvVlBR-QvJ"
      },
      "source": [
        "# Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6nzlr2z-Q0G"
      },
      "source": [
        "def get_lengths(tokens, eos_idx):\n",
        "  lengths = torch.cumsum(tokens == eos_idx, 1)\n",
        "  lengths = (lengths == 0).long().sum(-1)\n",
        "  lengths = lengths + 1 # +1 for <eos> token\n",
        "  return lengths"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqxGJwJp_n7v"
      },
      "source": [
        "def batch_preprocess(batch, pad_idx, eos_idx, reverse = False):\n",
        "  batch_pos, batch_neg = batch  #returning the positive and negative to containers\n",
        "  diff = batch_pos.size(1) - batch_neg.size(1) # filling them with pads if they're distinct in size\n",
        "\n",
        "  if diff < 0: \n",
        "    pad = torch.full_like(batch_neg[:, :-diff], pad_idx)\n",
        "    batch_pos = torch.cat((batch_pos, pad), 1)\n",
        "\n",
        "  elif diff > 0:\n",
        "    pad = torch.full_like(batch_pos[:, :diff], pad_idx)\n",
        "    batch_neg = torch.cat((batch_neg, pad), 1)\n",
        "\n",
        "  pos_styles = torch.ones_like(batch_pos[:, 0])\n",
        "  neg_styles = torch.zeros_like(batch_neg[:, 0])\n",
        "\n",
        "\n",
        "  if reverse:\n",
        "    batch_pos, batch_neg = batch_neg, batch_pos\n",
        "    pos_styles, neg_styles = neg_styles, pos_stlyes\n",
        "\n",
        "  tokens = torch.cat((batch_pos, batch_neg), 0)\n",
        "  lengths = get_lengths(tokens, eos_idx)\n",
        "  styles = torch.cat((pos_styles, neg_styles), 0)\n",
        "\n",
        "\n",
        "  return tokens, lengths, styles\n",
        "\n",
        "  \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PQTlLJl7aSv"
      },
      "source": [
        "def d_step(config, vocab, model_F, model_D, optimizer_D, batch, temperature):\n",
        "  model_F.eval()\n",
        "  pad_idx = vocab.stoi['<pad>']\n",
        "  eos_idx = vocab.stoi['<eos>']\n",
        "  vocab_size = len(vocab)\n",
        "  loss_fn = nn.NLLLoss(reduction = 'none')\n",
        "\n",
        "\n",
        "  inp_tokens, inp_lengths, raw_styles = batch_preprocess(batch, pad_idx, eos_idx)\n",
        "  rev_styles = 1 - raw_styles\n",
        "  batch_size = inp_tokens.size(0)\n",
        "  with torch.no_grad():\n",
        "    raw_gen_log_probs = model_F(\n",
        "        inp_tokens,\n",
        "        None,\n",
        "        inp_lengths,\n",
        "        raw_styles,\n",
        "        generate = True,\n",
        "        differentiable_decode = True,\n",
        "        temperature = temperature,\n",
        "    )\n",
        "    rev_gen_log_probs = model_F(\n",
        "        inp_tokens,\n",
        "        None,\n",
        "        inp_lengths,\n",
        "        rev_styles,\n",
        "        generate = True,\n",
        "        differentiable_decode = True,\n",
        "        temperature = temperature,\n",
        "    )\n",
        "\n",
        "\n",
        "    raw_gen_soft_tokens = raw_gen_log_probs.exp()\n",
        "    raw_gen_lengths = get_lengths(raw_gen_soft_tokens.argmax(-1), eos_idx)\n",
        "\n",
        "    rev_gen_soft_tokens = rev_gen_log_probs.exp()\n",
        "    rev_gen_lengths = get_lengths(rev_gen_soft_tokens.argmax(-1), eos_idx)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if config.discriminator_method == 'Multi':\n",
        "      gold_log_probs = model_D(inp_tokens, inp_lengths)\n",
        "      gold_labels = raw_styles + 1\n",
        "\n",
        "      raw_gen_log_probs = model_D(raw_gen_soft_tokens, raw_gen_lengths)\n",
        "      rev_gen_log_probs = model_D(rev_gen_soft_tokens, rev_gen_lengths)\n",
        "      gen_log_probs = torch.cat((raw_gen_log_probs, rev_gen_log_probs), 0)\n",
        "      raw_gen_labels = raw_styles + 1\n",
        "      rev_gen_labels = torch.zeros_like(rev_styles)\n",
        "      gen_labels = torch.cat((raw_gen_labels, rev_gen_labels), 0)\n",
        "\n",
        "    else:\n",
        "      raw_gold_log_probs = model_D(inp_tokens, inp_lengths, raw_styles)\n",
        "      rev_gold_log_probs = model_D(inp_tokens, inp_lengths, rev_styles)\n",
        "      gold_lob_probs = torch.cat((raw_gold_log_probs, rev_gold_log_probs), 0)\n",
        "      raw_gold_labels = torch.ones_like(raw_styles)\n",
        "      rev_gold_labels = torch.zeros_like(rev_styles)\n",
        "      gold_labels = torch.cat((raw_gold_labels, rev_gold_labels), 0)\n",
        "\n",
        "\n",
        "      raw_gen_log_probs = model_D(raw_gen_soft_tokens, raw_gen_lengths, raw_styles)\n",
        "      rev_gen_log_probs = model_D(rev_gen_soft_tokens, rev_gen_lengths, rev_styles)\n",
        "      gen_log_probs = torch.cat((raw_gen_log_probs, rev_gen_log_probs), 0)\n",
        "      raw_gen_labels = torch.ones_like(raw_styles)\n",
        "      rev_gen_labels = torch.zeros_like(rev_syles)\n",
        "      gen_labels = torch.cat((raw_gen_labels, rev_gen_labels), 0)\n",
        "\n",
        "\n",
        "    adv_log_probs = torch.cat((gold_log_probs, gen_log_probs), 0)\n",
        "    adv_labels = torch.cat((gold_labels, gen_labels), 0)\n",
        "    adv_loss = loss_fn(adv_log_probs, adv_labels)\n",
        "    assert len(adv_loss.size()) == 1\n",
        "    adv_loss = adv_loss.sum() / batch_size\n",
        "    loss = adv_loss \n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "    loss.requires_grad = True\n",
        "    loss.backward()\n",
        "\n",
        "    clip_grad_norm_(model_D.parameters(), 5)\n",
        "    optimizer_D.step()\n",
        "\n",
        "    model_F.train()\n",
        "\n",
        "\n",
        "    return adv_loss.item()\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wis_VFPv7aUk"
      },
      "source": [
        "def f_step(config, vocab, model_F, model_D, optimizer_F, batch, temperature, drop_decay, cyc_rec_enable=True):\n",
        "  model_D.eval()\n",
        "  pad_idx = vocab.stoi['<pad>']\n",
        "  eos_idx = vocab.stoi['<eos>']\n",
        "  unk_idx = vocab.stoi['<unk']\n",
        "  vocab_size = len(vocab)\n",
        "  loss_fn = nn.NLLLoss(reduction = 'none')\n",
        "\n",
        "\n",
        "  inp_tokens, inp_lengths, raw_styles = batch_preprocess(batch, pad_idx, eos_idx)\n",
        "  rev_styles = 1 - raw_styles\n",
        "  batch_size = inp_tokens.size(0)\n",
        "  token_mask = (inp_tokens != pad_idx).float()\n",
        "\n",
        "\n",
        "\n",
        "  optimizer_F.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "  #se,f reconstruction loss???\n",
        "\n",
        "\n",
        "\n",
        "  noise_inp_tokens = word_drop(\n",
        "      inp_tokens,\n",
        "      inp_lengths,\n",
        "      config.inp_drop_prob * drop_decay,\n",
        "      vocab\n",
        "  )\n",
        "\n",
        "  noise_inp_lengths = get_lengths(noise_inp_tokens, eos_idx)\n",
        "\n",
        "  slf_log_probs = model_F(\n",
        "      noise_inp_tokens,\n",
        "      inp_tokens,\n",
        "      noise_inp_lengths,\n",
        "      raw_styles,\n",
        "      generate = False,\n",
        "      differentiable_decode = False,\n",
        "      temperature = temperature,\n",
        "  )\n",
        "\n",
        "  slf_rec_loss = loss_fn(slf_log_probs.transpose(1, 2), inp_tokens) * token_mask\n",
        "  slf_rec_loss = slf_rec_loss.sum() / batch_size\n",
        "  slf_rec_loss *= config.slf_factor\n",
        "\n",
        "  slf_rec_loss.backward()\n",
        "\n",
        "\n",
        "  #cycle consistency loss\n",
        "\n",
        "  if not cyc_rec_enable:\n",
        "    optimizer_F.step()\n",
        "    model_D.train()\n",
        "    return slf_rec_loss.item(), 0, 0\n",
        "\n",
        "  \n",
        "  gen_log_probs = model_F(\n",
        "      inp_tokens,\n",
        "      None,\n",
        "      inp_lengths,\n",
        "      rev_styles,\n",
        "      generate=True,\n",
        "      differentiable_decode = True,\n",
        "      temperature = temperature,\n",
        "  )\n",
        "\n",
        "  gen_soft_tokens = gen_log_probs.exp()\n",
        "  gen_lengths = get_lengths(gen_soft_tokens.argmax(-1), eos_idx)\n",
        "\n",
        "\n",
        "  cyc_log_probs = model_F(\n",
        "      gen_soft_tokens,\n",
        "      inp_tokens,\n",
        "      gen_lengths,\n",
        "      raw_styles,\n",
        "      generate=False,\n",
        "      differentiable_decode=False,\n",
        "      temperature=temperature,\n",
        "  )\n",
        "\n",
        "  cyc_rec_loss = loss_fn(cyc_log_probs.transpose(1,2), inp_tokens) * token_mask\n",
        "  cyc_rec_loss = cyc_rec_loss.sum() / batch_size\n",
        "  cyc_rec_loss *= config.cyc_factor\n",
        "\n",
        "\n",
        "  #style consistency loss\n",
        "\n",
        "  adv_log_probs = model_D(gen_soft_tokens, gen_lengths, rev_styles)\n",
        "  if config.discriminator_method == 'Multi':\n",
        "    adv_labels = rev_styles + 1\n",
        "\n",
        "  else:\n",
        "    adv_labels = torch.ones_like(rev_styles)\n",
        "\n",
        "\n",
        "  adv_loss = loss_fn(adv_log_probs, adv_labels)\n",
        "  adv_loss = adv_loss.sum() / batch_size\n",
        "  adv_loss *= config.adv_factor\n",
        "\n",
        "\n",
        "  (cyc_rec_loss + adv_loss).backward()\n",
        "\n",
        "  #update parameters\n",
        "\n",
        "  clip_grad_norm_(model_F.parameters(), 5)\n",
        "  optimizer_F.step()\n",
        "\n",
        "  model_D.train()\n",
        "\n",
        "  return slf_rec_loss.item(), cyc_rec_loss.item(), adv_loss.item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KueR7qBQ7aY6"
      },
      "source": [
        "def train(config, vocab, model_F, model_D, train_iters, dev_iters, test_iters):\n",
        "  optimizer_F = optim.Adam(model_F.parameters(), lr=config.lr_F, weight_decay=config.L2)\n",
        "  optimizer_D = optim.Adam(model_D.parameters(), lr=config.lr_D, weight_decay=config.L2)\n",
        "\n",
        "  #declaring history list for losses\n",
        "  his_d_adv_loss=[]\n",
        "  his_f_slf_loss=[]\n",
        "  his_f_cyc_loss=[]\n",
        "  his_f_adv_loss=[]\n",
        "\n",
        "  #writer = SummaryWriter(config.lor_dir)\n",
        "  global_step=0\n",
        "  model_F.train()\n",
        "  model_D.train()\n",
        "\n",
        "\n",
        "  config.save_folder = config.save_path + '/' + str(time.strftime('%b%d%H%M%S', time.localtime()))\n",
        "  os.makedirs(config.save_folder)\n",
        "  os.makedirs(config.save_folder + '/ckpts')\n",
        "  print('Save Path:', config.save_folder)\n",
        "\n",
        "\n",
        "  print('Model F pretraining......')\n",
        "  for i, batch in enumerate(train_iters):\n",
        "    if i>= config.F_pretrain_iter:\n",
        "      break\n",
        "\n",
        "    slf_loss, cyc_loss, _ = f_step(config, vocab, model_F, model_D, optimizer_F, batch, 1.0, 1.0, False)\n",
        "    his_f_slf_loss.append(slf_loss)\n",
        "    his_f_cyc_loss.append(cyc_loss)\n",
        "\n",
        "    if (i + 1) % 10 == 0:\n",
        "      avg_f_slf_loss = np.mean(his_f_slf_loss)\n",
        "      avg_f_cyc_loss = np.mean(his_f_cyc_loss)\n",
        "      his_f_slf_loss = []\n",
        "      his_f_cyc_loss = []\n",
        "      print('[iter: {}] slf_loss:{:.4f}, rec_loss:{:.4f}'.format(i + 1, avg_f_slf_loss, avg_f_cyc_loss))\n",
        "\n",
        "\n",
        "  def calc_temperature(temperature_config, step):\n",
        "    num = len(temperature_config)\n",
        "    for i in range(num):\n",
        "      t_a, s_a = temperature_config[i]\n",
        "      if i == num - 1:\n",
        "        return t_a\n",
        "\n",
        "      t_b, s_b = temperature_config[i+1]\n",
        "      if s_a <= step < s_b:\n",
        "        k = (step - s_a) / (s_b - s_a)\n",
        "        temperature = (1 - k) * t_a + k * t_b\n",
        "        return temperature\n",
        "\n",
        "\n",
        "  batch_iters = iter(train_iters)\n",
        "  while True:\n",
        "    drop_decay = calc_temperature(config.drop_rate_config, global_step)\n",
        "    temperature = calc_temperature(config.temperature_config, global_step)\n",
        "    batch = next(batch_iters)\n",
        "\n",
        "    for _ in range(config.iter_D):\n",
        "      batch = next(batch_iters)\n",
        "      d_adv_loss = d_step(config, vocab, model_F, model_D, optimizer_D, batch, temperature)\n",
        "      his_d_adv_loss.append(d_adv_loss)\n",
        "\n",
        "    for _ in range(config.iter_F):\n",
        "      batch = next(batch_iters)\n",
        "      f_slf_loss, f_cyc_loss, f_adv_loss = f_step(config, vocab, model_F, model_D, optimizer_F, batch, temperature, drop_decay)\n",
        "      his_f_slf_loss.append(f_slf_loss)\n",
        "      his_f_cyc_loss.append(f_cyc_loss)\n",
        "      his_f_adv_loss.append(f_adv_loss)\n",
        "\n",
        "    global_step += 1\n",
        "    #writer.add_scalar('rec_loss', rec_loss.item(), global_step)\n",
        "    #writer.add_scalar('loss', loss.item(), global_step)\n",
        "\n",
        "    if global_step % config.log_steps == 0:\n",
        "      avg_d_adv_loss = np.mean(his_d_adv_loss)\n",
        "      avg_f_slf_loss = np.mean(his_f_slf_loss)\n",
        "      avg_f_cyc_loss = np.mean(his_f_cyc_loss)\n",
        "      avg_f_adv_loss = np.mean(his_f_adv_loss)\n",
        "      \n",
        "      log_str = '[iter {}] d_adv_loss: {:.4f} ' + \\\n",
        "                'f_slf_loss: {:.4f} f_cyc_loss: {:.4f} ' + \\\n",
        "                'f_adv_loss: {:.4f} temp: {:.4f} drop: {:.4f}' \n",
        "\n",
        "      print(log_str.format(\n",
        "          global_step, avg_d_adv_loss,\n",
        "          avg_f_slf_loss, avg_f_cyc_loss,avg_f_adv_loss,\n",
        "          temperature, config.inp_drop_prob * drop_decay\n",
        "      ))\n",
        "\n",
        "    if global_step % config.eval_steps == 0:\n",
        "      his_d_adv_loss = []\n",
        "      his_f_slf_loss = []\n",
        "      his_f_cyc_loss = []\n",
        "      his_f_adv_loss = []\n",
        "\n",
        "      torch.save(model_F.state_dict(), config.save_folder + '/ckpts' + str(global_step) + '_F.pth')\n",
        "      torch.save(model_D.state_dict(), config.save_folder + '/ckpts' + str(global_step) + '_D.pth')\n",
        "      #auto_eval(config, vocab, model_F, test_iters, global_step, temperature)\n",
        "      #for path, sub_writer in writer.all_writers.items():\n",
        "      # sub_writer.flush()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgUSoCx6573y"
      },
      "source": [
        "#Style Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzpSZHUg6AuJ"
      },
      "source": [
        "\n",
        "class StyleTransformer(nn.Module):\n",
        "    def __init__(self, config, vocab):\n",
        "        super(StyleTransformer, self).__init__()\n",
        "        num_styles, num_layers = config.num_styles, config.num_layers\n",
        "        d_model, max_length = config.d_model, config.max_length\n",
        "        h, dropout = config.h, config.dropout\n",
        "        learned_pos_embed = config.learned_pos_embed\n",
        "        load_pretrained_embed = config.load_pretrained_embed\n",
        "        \n",
        "        self.max_length = config.max_length\n",
        "        self.eos_idx = vocab.stoi['<eos>']\n",
        "        self.pad_idx = vocab.stoi['<pad>']\n",
        "        self.style_embed = Embedding(num_styles, d_model)\n",
        "        self.embed = EmbeddingLayer(\n",
        "            vocab, d_model, max_length,\n",
        "            self.pad_idx,\n",
        "            learned_pos_embed,\n",
        "            load_pretrained_embed,\n",
        "        )\n",
        "        self.sos_token = nn.Parameter(torch.randn(d_model))\n",
        "        self.encoder = Encoder(num_layers, d_model, len(vocab), h, dropout)\n",
        "        self.decoder = Decoder(num_layers, d_model, len(vocab), h, dropout)\n",
        "        \n",
        "    def forward(self, inp_tokens, gold_tokens, inp_lengths, style,\n",
        "                generate=False, differentiable_decode=False, temperature=1.0):\n",
        "        batch_size = inp_tokens.size(0)\n",
        "        max_enc_len = inp_tokens.size(1)\n",
        "        my_str = 'the length of max_enc_len is ' + str(max_enc_len)\n",
        "        print(my_str)\n",
        "\n",
        "        assert max_enc_len <= self.max_length\n",
        "\n",
        "        pos_idx = torch.arange(self.max_length).unsqueeze(0).expand((batch_size, -1))\n",
        "        pos_idx = pos_idx.to(inp_lengths.device)\n",
        "\n",
        "        src_mask = pos_idx[:, :max_enc_len] >= inp_lengths.unsqueeze(-1)\n",
        "        src_mask = torch.cat((torch.zeros_like(src_mask[:, :1]), src_mask), 1)\n",
        "        src_mask = src_mask.view(batch_size, 1, 1, max_enc_len + 1)\n",
        "\n",
        "        tgt_mask = torch.ones((self.max_length, self.max_length)).to(src_mask.device)\n",
        "        tgt_mask = (tgt_mask.tril() == 0).view(1, 1, self.max_length, self.max_length)\n",
        "\n",
        "        style_emb = self.style_embed(style).unsqueeze(1)\n",
        "\n",
        "        enc_input = torch.cat((style_emb, self.embed(inp_tokens, pos_idx[:, :max_enc_len])), 1)\n",
        "        memory = self.encoder(enc_input, src_mask)\n",
        "        \n",
        "        sos_token = self.sos_token.view(1, 1, -1).expand(batch_size, -1, -1)\n",
        "        \n",
        "        if not generate:\n",
        "            dec_input = gold_tokens[:, :-1]\n",
        "            max_dec_len = gold_tokens.size(1)\n",
        "            dec_input_emb = torch.cat((sos_token, self.embed(dec_input, pos_idx[:, :max_dec_len - 1])), 1)\n",
        "            log_probs = self.decoder(\n",
        "                dec_input_emb, memory,\n",
        "                src_mask, tgt_mask[:, :, :max_dec_len, :max_dec_len],\n",
        "                temperature\n",
        "            )\n",
        "        else:\n",
        "            \n",
        "            log_probs = []\n",
        "            next_token = sos_token\n",
        "            prev_states = None\n",
        "            \n",
        "            for k in range(self.max_length):\n",
        "                log_prob, prev_states = self.decoder.incremental_forward(\n",
        "                    next_token, memory,\n",
        "                    src_mask, tgt_mask[:, :, k:k+1, :k+1],\n",
        "                    temperature,\n",
        "                    prev_states\n",
        "                )\n",
        "\n",
        "                log_probs.append(log_prob)\n",
        "                \n",
        "                if differentiable_decode:\n",
        "                    next_token = self.embed(log_prob.exp(), pos_idx[:, k:k+1])\n",
        "                else:\n",
        "                    next_token = self.embed(log_prob.argmax(-1), pos_idx[:, k:k+1])\n",
        "\n",
        "                #if (pred_tokens == self.eos_idx).max(-1)[0].min(-1)[0].item() == 1:\n",
        "                #    break\n",
        "\n",
        "            log_probs = torch.cat(log_probs, 1)\n",
        "            \n",
        "            \n",
        "        return log_probs\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, config, vocab):\n",
        "        super(Discriminator, self).__init__()\n",
        "        num_styles, num_layers = config.num_styles, config.num_layers\n",
        "        d_model, max_length = config.d_model, config.max_length\n",
        "        h, dropout = config.h, config.dropout\n",
        "        learned_pos_embed = config.learned_pos_embed\n",
        "        load_pretrained_embed = config.load_pretrained_embed\n",
        "        num_classes = config.num_classes\n",
        "        \n",
        "        self.pad_idx = vocab.stoi['<pad>']\n",
        "        self.style_embed = Embedding(num_styles, d_model)\n",
        "        self.embed = EmbeddingLayer(\n",
        "            vocab, d_model, max_length,\n",
        "            self.pad_idx,\n",
        "            learned_pos_embed,\n",
        "            load_pretrained_embed\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn(d_model))\n",
        "        self.encoder = Encoder(num_layers, d_model, len(vocab), h, dropout)\n",
        "        self.classifier = Linear(d_model, num_classes)\n",
        "    \n",
        "    def forward(self, inp_tokens, inp_lengths, style=None):\n",
        "        batch_size = inp_tokens.size(0)\n",
        "        num_extra_token = 1 if style is None else 2\n",
        "        max_seq_len = inp_tokens.size(1)\n",
        "\n",
        "        pos_idx = torch.arange(max_seq_len).unsqueeze(0).expand((batch_size, -1)).to(inp_lengths.device)\n",
        "        mask = pos_idx >= inp_lengths.unsqueeze(-1)\n",
        "        for _ in range(num_extra_token):\n",
        "            mask = torch.cat((torch.zeros_like(mask[:, :1]), mask), 1)\n",
        "        mask = mask.view(batch_size, 1, 1, max_seq_len + num_extra_token)\n",
        "\n",
        "        cls_token = self.cls_token.view(1, 1, -1).expand(batch_size, -1, -1)\n",
        "\n",
        "        enc_input = cls_token\n",
        "        if style is not None:\n",
        "            style_emb = self.style_embed(style).unsqueeze(1)\n",
        "            enc_input = torch.cat((enc_input, style_emb), 1)\n",
        "            \n",
        "        enc_input = torch.cat((enc_input, self.embed(inp_tokens, pos_idx)), 1)\n",
        "        \n",
        "        encoded_features = self.encoder(enc_input, mask)\n",
        "        logits = self.classifier(encoded_features[:, 0])\n",
        "\n",
        "        return F.log_softmax(logits, -1)\n",
        "        \n",
        "        \n",
        "    \n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, vocab_size, h, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, h, dropout) for _ in range(num_layers)])\n",
        "        self.norm = LayerNorm(d_model)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        y = x\n",
        "\n",
        "        assert y.size(1) == mask.size(-1)\n",
        "            \n",
        "        for layer in self.layers:\n",
        "            y = layer(y, mask)\n",
        "\n",
        "        return self.norm(y)\n",
        "        \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, vocab_size, h, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, h, dropout) for _ in range(num_layers)])\n",
        "        self.norm = LayerNorm(d_model)\n",
        "        self.generator = Generator(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask, temperature):\n",
        "        y = x\n",
        "\n",
        "        assert y.size(1) == tgt_mask.size(-1)\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            y = layer(y, memory, src_mask, tgt_mask)\n",
        "\n",
        "        return self.generator(self.norm(y), temperature)\n",
        "    def incremental_forward(self, x, memory, src_mask, tgt_mask, temperature, prev_states=None):\n",
        "        y = x\n",
        "\n",
        "        new_states = []\n",
        "\n",
        "                                            \n",
        "        for i, layer in enumerate(self.layers):\n",
        "            y, new_sub_states = layer.incremental_forward(\n",
        "                y, memory, src_mask, tgt_mask,\n",
        "                prev_states[i] if prev_states else None\n",
        "            )\n",
        "\n",
        "            new_states.append(new_sub_states)\n",
        "        \n",
        "        new_states.append(torch.cat((prev_states[-1], y), 1) if prev_states else y)\n",
        "        y = self.norm(new_states[-1])[:, -1:]\n",
        "        \n",
        "        return self.generator(y, temperature), new_states\n",
        "    \n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, temperature):\n",
        "        return F.log_softmax(self.proj(x) / temperature, dim=-1)\n",
        "\n",
        "class EmbeddingLayer(nn.Module):\n",
        "    def __init__(self, vocab, d_model, max_length, pad_idx, learned_pos_embed, load_pretrained_embed):\n",
        "        super(EmbeddingLayer, self).__init__()\n",
        "        self.token_embed = Embedding(len(vocab), d_model)\n",
        "        self.pos_embed = Embedding(max_length, d_model)\n",
        "        self.vocab_size = len(vocab)\n",
        "        if load_pretrained_embed:\n",
        "            self.token_embed = nn.Embedding.from_pretrained(vocab.vectors)\n",
        "            print('embed loaded.')\n",
        "    def forward(self, x, pos):\n",
        "        if len(x.size()) == 2:\n",
        "            y = self.token_embed(x) + self.pos_embed(pos)\n",
        "        else:\n",
        "            y = torch.matmul(x, self.token_embed.weight) + self.pos_embed(pos)\n",
        "\n",
        "        return y\n",
        "    \n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, h, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, h, dropout)\n",
        "        self.pw_ffn = PositionwiseFeedForward(d_model, dropout)\n",
        "        self.sublayer =  nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(2)])\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.pw_ffn)\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, h, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, h, dropout)\n",
        "        self.src_attn = MultiHeadAttention(d_model, h, dropout)\n",
        "        self.pw_ffn = PositionwiseFeedForward(d_model, dropout)\n",
        "        self.sublayer = nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(3)])\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.pw_ffn)\n",
        "\n",
        "    def incremental_forward(self, x, memory, src_mask, tgt_mask, prev_states=None):\n",
        "        new_states = []\n",
        "        m = memory\n",
        "\n",
        "        x = torch.cat((prev_states[0], x), 1) if prev_states else x\n",
        "        new_states.append(x)\n",
        "        x = self.sublayer[0].incremental_forward(x, lambda x: self.self_attn(x[:, -1:], x, x, tgt_mask))\n",
        "        x = torch.cat((prev_states[1], x), 1) if prev_states else x\n",
        "        new_states.append(x)\n",
        "        x = self.sublayer[1].incremental_forward(x, lambda x: self.src_attn(x[:, -1:], m, m, src_mask))\n",
        "        x = torch.cat((prev_states[2], x), 1) if prev_states else x\n",
        "        new_states.append(x)\n",
        "        x = self.sublayer[2].incremental_forward(x, lambda x: self.pw_ffn(x[:, -1:]))\n",
        "        return x, new_states  \n",
        "   \n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, h, dropout):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.head_projs = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, query, key, value, mask):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
        "                             for x, l in zip((query, key, value), self.head_projs)]\n",
        "\n",
        "        attn_feature, _ = scaled_attention(query, key, value, mask)\n",
        "\n",
        "        attn_concated = attn_feature.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
        "\n",
        "        return self.fc(attn_concated)\n",
        "\n",
        "def scaled_attention(query, key, value, mask):\n",
        "    d_k = query.size(-1)\n",
        "    scores = query.matmul(key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    scores.masked_fill_(mask, float('-inf'))\n",
        "    attn_weight = F.softmax(scores, -1)\n",
        "    attn_feature = attn_weight.matmul(value)\n",
        "\n",
        "    return attn_feature, attn_weight\n",
        "    \n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, dropout):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            Linear(d_model, 4 * d_model),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            Linear(4 * d_model, d_model),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self, d_model, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.layer_norm = LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, sublayer):\n",
        "        y = sublayer(self.layer_norm(x))\n",
        "        return x + self.dropout(y)\n",
        "\n",
        "    def incremental_forward(self, x, sublayer):\n",
        "        y = sublayer(self.layer_norm(x))\n",
        "        return x[:, -1:] + self.dropout(y)\n",
        "    \n",
        "def Linear(in_features, out_features, bias=True, uniform=True):\n",
        "    m = nn.Linear(in_features, out_features, bias)\n",
        "    if uniform:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "    else:\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "    if bias:\n",
        "        nn.init.constant_(m.bias, 0.)\n",
        "    return m\n",
        "\n",
        "def Embedding(num_embeddings, embedding_dim, padding_idx=None):\n",
        "    m = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n",
        "    nn.init.xavier_uniform_(m.weight)\n",
        "    nn.init.constant_(m.weight[padding_idx], 0)\n",
        "    return m\n",
        "\n",
        "def LayerNorm(embedding_dim, eps=1e-6):\n",
        "    m = nn.LayerNorm(embedding_dim, eps)\n",
        "    return m"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaCo6EJK6W1C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1g8DYXb6XC-"
      },
      "source": [
        "#Start???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9742QTM6Ys-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL7wBKmi-df0"
      },
      "source": [
        "train_iters, dev_iters, test_iters, vocab = load_dataset(config)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuM3lD7Bhdsa"
      },
      "source": [
        "#index2word = vocab.itos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJHJsI6ghnIT"
      },
      "source": [
        "#vocab.stoi['<unk>']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmFOz8lchhAq"
      },
      "source": [
        "#index2word[pad_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBzZapIw6QJS",
        "outputId": "39f81581-a8f3-4651-d501-c334ea9db59d"
      },
      "source": [
        "print('Vocab size:', len(vocab))\n",
        "model_F = StyleTransformer(config, vocab).to(config.device)\n",
        "model_D = Discriminator(config, vocab).to(config.device)\n",
        "print(config.discriminator_method)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 34685\n",
            "Multi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi6o3bjI6dME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "71940b8f-cb36-4acc-d704-09bdaf376231"
      },
      "source": [
        "train(config, vocab, model_F, model_D, train_iters, dev_iters, test_iters)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e39ecf08a079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8963lJbImom"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCP4jO8tImzb"
      },
      "source": [
        "#sAVED stuff\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlzouiIeL9xO"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lagmhsOTIojf",
        "outputId": "9d5b75c0-9d4f-41d5-a838-04faae099068"
      },
      "source": [
        "model_F.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/save/Aug08180829/ckpts1175_F.pth',map_location=device))\n",
        "model_F.eval()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StyleTransformer(\n",
              "  (style_embed): Embedding(2, 256)\n",
              "  (embed): EmbeddingLayer(\n",
              "    (token_embed): Embedding(34685, 256)\n",
              "    (pos_embed): Embedding(400, 256)\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (src_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (2): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (src_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (2): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (src_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (2): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): DecoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (src_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (2): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "    (generator): Generator(\n",
              "      (proj): Linear(in_features=256, out_features=34685, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVtr7mV-Icar",
        "outputId": "08b46b98-a298-47c9-e22a-8ab4d9cd641a"
      },
      "source": [
        "model_D.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/save/Aug08180829/ckpts1175_D.pth',map_location=device))\n",
        "model_D.eval()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (style_embed): Embedding(2, 256)\n",
              "  (embed): EmbeddingLayer(\n",
              "    (token_embed): Embedding(34685, 256)\n",
              "    (pos_embed): Embedding(400, 256)\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (head_projs): ModuleList(\n",
              "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (pw_ffn): PositionwiseFeedForward(\n",
              "          (mlp): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Dropout(p=0, inplace=False)\n",
              "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hLTav9yIjya"
      },
      "source": [
        "#Save predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0yzDojyLE6"
      },
      "source": [
        "gold_text = []\n",
        "raw_output = []\n",
        "rev_output = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSZP3K8LyVki"
      },
      "source": [
        "#probably should have these in the loop\n",
        "inp_styles\n",
        "raw_styles = torch.full_like(inp_tokens[:, 0], 0)\n",
        "rev_styles = 1 - raw_styles\n",
        "rev_styles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj0Ps77ZJ7xN"
      },
      "source": [
        "loss_fn = nn.NLLLoss(reduction = 'none')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "yTxL7TbuJoRz",
        "outputId": "e3d66d1a-9cca-4f90-97e1-96fbbbb7dee8"
      },
      "source": [
        "print(len(vocab))\n",
        "pad_idx = vocab.stoi['pad']\n",
        "eos_idx = vocab.stoi['eos']\n",
        "for batch in train_iters:\n",
        "    inp_tokens, inp_lengths, inp_styles=batch_preprocess(batch,pad_idx,eos_idx)\n",
        "    rev_styles = 1 - inp_styles\n",
        "     with torch.no_grad():\n",
        "         raw_log_probs = model_F(\n",
        "             inp_tokens,\n",
        "             None,\n",
        "             inp_lengths,\n",
        "             raw_styles,\n",
        "             generate=True,\n",
        "             differentiable_decode=False,\n",
        "            temperature=1,\n",
        "  )\n",
        "            \n",
        "  with torch.no_grad():\n",
        "      rev_log_probs = model_F(\n",
        "          inp_tokens, \n",
        "          None,\n",
        "          inp_lengths,\n",
        "          rev_styles,\n",
        "          generate=True,\n",
        "          differentiable_decode=False,\n",
        "          temperature=1,\n",
        "      )\n",
        "                \n",
        "gold_text += tensor2text(vocab, inp_tokens.cpu())\n",
        "raw_output += tensor2text(vocab, raw_log_probs.argmax(-1).cpu())\n",
        "rev_output += tensor2text(vocab, rev_log_probs.argmax(-1).cpu())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9df2b9a0e70b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0minp_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mraw_styles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mgenerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mdifferentiable_decode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_styles' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHoex5Mevf_6",
        "outputId": "96321cc5-f8ab-4959-fd87-f214f95927d5"
      },
      "source": [
        "gold_text"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Variable numbers of immature white blood cells and platelets also may be present in the blood .',\n",
              " 'Blunt trauma may cause ecchymosis ( eg , the transverse , linear ecchymosis termed seat belt sign ) , but this finding has poor sensitivity and specificity .',\n",
              " 'For such people , doctors often do the following : A complete blood count ( including the number and proportion of different types of white blood cells ) ; A chest x-ray ; Urinalysis .',\n",
              " 'If adrenal crisis is suspected , confirmation of Addison disease by ACTH stimulation testing is deferred until the patient has recovered .',\n",
              " 'However , if multiple mononeuropathy involves many nerves , it may be difficult to distinguish from polyneuropathy .',\n",
              " 'These variants may cause the gene to malfunction , possibly resulting in increased production of beta- amyloid .',\n",
              " 'Doctors then do a physical examination .',\n",
              " 'Flexible spending accounts ( ) are offered by some employers .',\n",
              " 'Narrowing of the airways is often caused by abnormal sensitivity of cholinergic receptors , which cause the muscles of the airways to contract when they should not .',\n",
              " 'Many cases are idiopathic ( see table Causes of Myocarditis ) .',\n",
              " 'In addition , mutations in the calreticulin gene ( CALR ) and other genes have been found in some people with polycythemia vera .',\n",
              " 'Transvaginal ultrasonography can usually confirm the diagnosis .',\n",
              " 'Hydrocolloid ( oxygen -retaining and ) patches protect pressure sores and provide a healthy environment for sores with light or moderate drainage .',\n",
              " 'Levels exceeding normal ( > 20 ng/mL ) , especially when increasing , strongly suggest HCC .',\n",
              " 'Alternatively , some of these injuries can be managed with arterial embolization , in which doctors pass a catheter through a blood vessel in the upper thigh into the bleeding kidney vessel .',\n",
              " 'In the emergency department , if the mechanism of injury suggests potentially severe or multiple injuries ( as in a high - speed motor vehicle crash or fall from a height ) , patients are first evaluated from head to toe for serious injuries to all organ systems and , if needed , are resuscitated ( see Approach to the Trauma Patient ) .',\n",
              " 'The sudden blocking of an artery of the lung is not only caused by blood clots .',\n",
              " 'The remainder of spinal cord injuries are attributed to assault ( 12 % ) , sports ( 10 % ) , and work-related accidents .',\n",
              " \"The sample may be taken from the woman 's vagina or by amniocentesis .\",\n",
              " 'Severe , frequently intermittent , often pleuritic pain begins suddenly in the epigastrium , abdomen , or lower anterior chest , with fever and often headache , sore throat , and malaise .',\n",
              " 'Having a bowel movement may also be difficult .',\n",
              " 'Screening tests are tests that are done in asymptomatic patients at risk .',\n",
              " 'People who drink a moderate amount of alcohol seem to have a lower risk of coronary artery disease than do people who drink too much or do not drink at all .',\n",
              " 'Historically , radiation therapy was sometimes given to patients at risk of skeletal deformity , vision loss secondary to proptosis , pathologic fractures , vertebral collapse , or spinal cord injury or to patients with severe pain .',\n",
              " 'The newer anticoagulants taken by mouth ( rivaroxaban , apixaban , edoxaban , dabigatran ) tend to cause fewer episodes of serious bleeding than warfarin , but currently there is an antidote for only one of these drugs ( dabigatran ) if excessive bleeding does occur .',\n",
              " '( See also Overview of Foot and Ankle Disorders .',\n",
              " 'Sometimes it is used for allergies to animal dander , but such treatment is unlikely to be useful .',\n",
              " 'H , D , and on behalf of the International Tuberous Sclerosis Complex Consensus Group : Tuberous sclerosis complex diagnostic criteria update : Recommendations of the 2012 International Tuberous Sclerosis Complex Consensus Conference .',\n",
              " 'To be useful , tests used for screening must Be accurate ; Be relatively inexpensive ; little risk ; Cause little or no discomfort ; Improve outcomes .',\n",
              " 'Hb usually is > 8 g/dL unless an additional mechanism contributes to anemia , such as concomitant iron deficiency ( see table Differential Diagnosis of Microcytic Anemia Due to Decreased RBC Production ) .',\n",
              " 'Both types cause a fever that comes and goes and a rash .',\n",
              " 'Infection of the urethra with bacteria ( or with protozoa , viruses , or fungi ) occurs when organisms that gain access to it acutely or chronically colonize the numerous periurethral glands in the bulbous and pendulous portions of the male urethra and in the entire female urethra .',\n",
              " 'In studies of people with arthritis , feverfew did not relieve symptoms .',\n",
              " 'Eye patching is contraindicated because it produces a dark warm environment that favors bacterial growth and prevents administration of topical drugs .',\n",
              " 'Before surgery is done , a neurosurgeon and a neurologist explain the risks and benefits of surgery to the parents .',\n",
              " 'Relative contraindications balance the urgency of the procedure ( eg , in an acute myocardial infarction vs an elective case ) and the severity of the disorder .',\n",
              " 'The diagnosis may be confirmed by x-rays taken to rule out arthritis or a fracture of the sesamoid bone .',\n",
              " 'DNA methylation tends to a gene .',\n",
              " 'Sometimes a syphilis infection reactivates in people who have HIV infection .',\n",
              " 'Sexual transmission and vertical transmission of hepatitis C from mother to infant are relatively rare .',\n",
              " 'Doctors watch the newborn breathe and count the number of breaths in a minute .',\n",
              " 'Many patients with IBS are ; however , CBC , biochemical profile ( including liver tests ) , serologic markers for celiac disease ( IgA with an IgA level ) , stool examination for infection ( in patients with diarrhea predominance ) , thyroid-stimulating hormone and calcium for patients with constipation , and flexible sigmoidoscopy or colonoscopy should be considered .',\n",
              " 'However , in countries where infectious diseases and undernutrition are common causes of infant death and where safe , affordable infant formula is not available , the World Health Organization recommends that mothers breastfeed .',\n",
              " 'is a more s elective adenosine agonist than either dipyridamole or adenosine and is non-inferior for the diagnosis of ischemia with fewer adverse effects and greater ease of administration .',\n",
              " 'Most soft-tissue injuries heal well and result in few problems .',\n",
              " 'This insurance is not recommended for people with few assets and may not be worthwhile for people who can easily pay for long-term care .',\n",
              " 'They may not need to be seen , particularly if they have typical cold symptoms and are otherwise healthy .',\n",
              " 'A newer topical gel , ingenol mebutate , can be applied for 2 to 3 days to treat actinic keratoses and has the advantage of a short course of therapy .',\n",
              " 'People are given pain relievers and are asked to cough or breathe deeply about once an hour to prevent lung problems .',\n",
              " 'Polyarticular pain caused by articular sources may result from the following : Inflammation ( eg , infection , crystal -induced arthritis , systemic inflammatory disorders such as RA and psoriatic arthritis ) ; Mechanical or other noninflammatory disorders ( eg , osteoarthritis , hypermobility syndromes ) .',\n",
              " 'Detachment of the placenta occurs in 0.4 to 1.5 % of all pregnancies .',\n",
              " \"The American Journal of Gastroenterology 's guidelines recommend colonoscopy every 10 years or annual FIT as the preferred screening tests .\",\n",
              " 'Because many drugs can interact with warfarin , people who take anticoagulants should be sure to check with their doctor before taking any other drugs , including drugs that can be obtained without a prescription ( over-the-counter drugs ) such as acetaminophen or aspirin , herbal preparations , and dietary supplements .',\n",
              " 'Pain can be intense and persistent when the pulp is severely involved ( pulpitis ) .',\n",
              " 'Heparin during pregnancy pad',\n",
              " 'Likelihood of achieving an SVR with new interferon -free regimens seems to depend mostly on the following : P retreatment viral load ; Degree of liver fibrosis ; Response to prior treatment .',\n",
              " 'If caused by a virus , the destruction may stop after a period of time .',\n",
              " 'Treatment consists of a prolonged course of antimicrobial therapy ( 1 ) .',\n",
              " 'Stool that is pale and not the normal gold color suggests there may be cholestasis .',\n",
              " 'Diagnosis of neonatal HBV infection is by serologic testing , including measurement of HBsAg , HBeAg , antibody to hepatitis B e antigen ( anti-HBe ) , and of HBV DNA in blood .',\n",
              " 'Severe reactions require emergency treatment in the hospital .',\n",
              " 'Confirm the diagnosis by the response to atropine and sometimes RBC cholinesterase levels .',\n",
              " 'If symptoms have been more frequent or longer-lasting than usual , doctors may do sigmoidoscopy or colonoscopy and a blood count .',\n",
              " 'Recurrent disease in the graft is uncommon ( < 5 % ) , but risk may be increased in blacks , females , and younger patients .',\n",
              " '( See also Introduction to Disorders of Kidney Tubules .',\n",
              " 'For attacks , parenteral triptans , dihydroergotamine , or 100 % oxygen',\n",
              " 'Treatment depends on type of growth .',\n",
              " 'However , a dilated cervix plus passage of fetal tissue and crampy abdominal pain strongly suggests spontaneous abortion , and septic abortion is usually apparent from the circumstances and signs of severe infection ( fever , toxic appearance , purulent or bloody discharge ) .',\n",
              " 'Polymyalgia rheumatica seems to be more common .',\n",
              " 'Breastfeeding is done at least every 4 h during the day and every 6 h at night .',\n",
              " 'Often , doctors do endovascular stent graft repair , which does not require surgery on the abdomen .',\n",
              " 'Diagnosis is made by clinical criteria .',\n",
              " 'Centers for Disease Control and Prevention : Hepatitis C FAQs for the Public .',\n",
              " 'During horizontal gaze to the side opposite the affected eye , images are horizontally displaced , causing diplopia ; nystagmus often occurs in the abducting eye .',\n",
              " 'Instead measures to prevent transmission ( such as condoms ) are recommended whenever people who may have been exposed to the Zika virus have sexual intercourse ( including vaginal , anal , and oral sex ) .',\n",
              " 'If these patients have symptoms , they can alternatively be treated for 5 days with dimercaprol 50 mg/m2 via deep IM injection q 4 h plus 1000 mg/m2 IV once/ day .',\n",
              " 'Because ventilation and supplemental oxygen may injure the lungs , doctors try to remove newborns from ventilators as soon as possible and minimize the use of supplemental oxygen .',\n",
              " '2 .',\n",
              " 'The term organic dust toxic syndrome ( ) has been used to encompass the flu-like symptoms that occur in people exposed to organic dust that is contaminated with bacteria .',\n",
              " ', JM , CM : Melanonychia striata : behind the black curtain .',\n",
              " 'The doctor can send a sample taken by swabbing the nose or throat to be tested .',\n",
              " 'Adult Schistosoma worms live and within venules of the mesentery ( typically S. japonicum and S. mansoni ) or bladder ( typically S. haematobium ) .',\n",
              " 'These probes can be used to test the entire genotype .',\n",
              " 'Percutaneous core needle biopsy is preferred to surgical biopsy .',\n",
              " 'The abdomen is checked for swelling and tenderness .',\n",
              " 'The effects , desired and undesired , of all drugs taken should be determined because these effects usually include the spectrum of drug interactions .',\n",
              " 'People express what they do and do not want to experience .',\n",
              " 'Chemical carcinogens can induce gene mutations and result in uncontrolled growth and tumor formation ( see table Common Chemical Carcinogens ) .',\n",
              " 'A permanent crown is then made in a dental laboratory , using the impression .',\n",
              " 'Patients who have primary immunodeficiencies may have nonimmune manifestations that can be recognized more easily than the immunodeficiencies .',\n",
              " 'Doctors also check the person for injuries resulting from the fainting episode .',\n",
              " 'In adults , vitamin K deficiency can result from Fat malabsorption ( eg , due to biliary obstruction , malabsorption disorders , cystic fibrosis , or resection of the small intestine ) ; Use of coumarin anticoagulants .',\n",
              " 'Most people have only one type of seizure .',\n",
              " 'Methimazole need only be given once a day , which improves adherence .',\n",
              " 'This information can help doctors determine which bones and other structures are damaged .',\n",
              " 'Nasal decongestants may reduce nasal obstruction .',\n",
              " 'Occasionally , surgery is needed to confirm the diagnosis .',\n",
              " 'Brushing with an electric toothbrush for 2 minutes is excellent ; brushing with a manual soft toothbrush for 3 to 4 minutes suffices .',\n",
              " 'American Kidney Fund pad',\n",
              " 'However , in some states , practitioners can extend the requirement pending medical .',\n",
              " 'Life span is not affected .',\n",
              " 'Patients with respiratory infections should be treated and have evidence that the infection has resolved before receiving inhalational anesthesia .',\n",
              " 'The intelligence quotient ( IQ ) tends to be slightly lower than that of other family members .',\n",
              " 'Children with the predominantly inattentive type may have no physical signs .',\n",
              " 'Langerhans cell histiocytosis can affect other organs ( such as the pituitary gland , bones , and the lymph nodes ) as well as the lungs .',\n",
              " 'Symptoms are generally more pronounced in patients with limited cardiopulmonary reserve or in whom the anemia developed very rapidly .',\n",
              " 'It may take up to 2 years .',\n",
              " '1 .',\n",
              " 'If cancer is detected in the lymph nodes , it is more likely to have spread to other parts of the body .',\n",
              " 'Tablets containing fixed combinations of ≥ 2 drugs are now widely used to simplify regimens and improve adherence .',\n",
              " 'If older people become less alert or less conscious of things around them , family members and friends may not notice or may assume that the change results from aging .',\n",
              " 'Most species are also sensitive to fluoroquinolones and tetracyclines .',\n",
              " 'Sometimes cultures of blood , cerebrospinal fluid , and material from the windpipe to look for infectious causes of respiratory distress ..',\n",
              " 'It usually develops 15 to 20 years after initial infection and typically does not affect patients before their 40s or 50s .',\n",
              " 'Osteomyelitis is an infection of the bone and is usually caused by bacteria .',\n",
              " 'Strabismus can be detected during well-child checkups through the history and eye examination .',\n",
              " 'Carcinoid tumors , including bronchial carcinoids , are among the cancers that cause paraneoplastic syndromes .',\n",
              " 'There is no specific treatment , but neurofibromas that cause severe symptoms may be removed surgically .',\n",
              " 'Other particles cause harm not by triggering allergic reactions but by being toxic to the cells of the airways and air sacs in the lung .',\n",
              " 'Gentle pressure is applied to the suprapatellar region to help drain extra fluid .',\n",
              " 'Doctors also measure levels of C-reactive protein ( which the liver produces in response to bodywide inflammation ) .',\n",
              " 'Prevention of graft-vs-host disease is with irradiation ( to damage DNA of the donor lymphocytes ) of all transfused blood products .',\n",
              " '.',\n",
              " 'Unilateral joint involvement helps distinguish secondary degenerative arthritis from osteoarthritis .',\n",
              " 'The diagnosis is based on examination of the voice box ( larynx ) , bronchial tubes , or esophagus .',\n",
              " 'If bacterial meningitis is suspected and the patient is very ill , antibiotics and corticosteroids are given immediately , even before lumbar puncture .',\n",
              " 'Echocardiography uses ultrasound waves to produce images of the heart ( ) .',\n",
              " 'Removal of the involved area may be very difficult but is indicated if perforation and general peritonitis are present .',\n",
              " 'The factors that most increase the chances of survival without permanent brain and lung damage are the following : Beginning resuscitation immediately ( most important ) ; Brief duration of submersion ; Cold water temperature ; Young age .',\n",
              " 'Patients who have a high risk of recurrence may benefit from its use .',\n",
              " 'Professional divers may undergo additional medical tests , such as those for heart and lung function , exercise stress , hearing , and vision , as well as bone x-rays .',\n",
              " 'There is no safe blood lead level in children , and even low blood lead levels have been shown to affect IQ , ability to pay attention , and academic achievement .',\n",
              " 'Leave 1/2 inch at the tip of the condom to collect semen .',\n",
              " 'Secondary hyperparathyroidism is common and can develop in renal failure before abnormalities in calcium or phosphate concentrations occur .',\n",
              " 'Magnetic resonance angiography ( MRA ) is a type of MRI that focuses on blood vessels rather than organs .',\n",
              " 'Hodgkin lymphoma is usually suspected in patients with painless lymphadenopathy or mediastinal adenopathy detected on physical exam or routine chest x-ray .',\n",
              " 'Even with treatment , there is a significant risk of death .',\n",
              " 'Acute retroviral syndrome usually begins within 1 to 4 weeks of infection and usually lasts 3 to 14 days .',\n",
              " 'Weight loss is also important in these people because excess weight contributes to complications of diabetes .',\n",
              " 'Mild to severe GI hemorrhage is the most common complication of peptic ulcer disease .',\n",
              " 'Most people have a normal life span , but if another disorder , such as lymphoma or an autoimmune disorder develops and is hard to treat , life span may be shortened .',\n",
              " 'The oral examination includes inspection for gum inflammation and caries and any localized swelling at the base of a tooth that may represent a pointing apical abscess .',\n",
              " 'Urine tests are done to determine whether the kidneys are affected .',\n",
              " 'Antithrombin is a plasma protein that inhibits thrombin and factors Xa , IXa , and XIa , thereby inhibiting thrombosis .',\n",
              " 'To diagnose nocardiosis , doctors examine a sample of infected tissue under a microscope or send the sample to a laboratory to be cultured .',\n",
              " 'Many patients with an elbow dislocation present with a shortened forearm and a very prominent olecranon ; the position of the bones may be difficult to determine because of swelling .',\n",
              " 'If it is not clear why a person is acting abnormally , doctors may do tests to rule out other possible causes of symptoms , such as low blood sugar or head injury .',\n",
              " 'Other symptoms of venous or arterial thrombosis may also develop .',\n",
              " 'These tumors arise from cells in the pancreas that produce insulin .',\n",
              " 'therapy is a possible cause , as are massive daily doses ( 150,000 to 350,000 units [ 50,000 to RAE ] ) of vitamin A or its metabolites , which are sometimes given for nodular acne or other skin disorders .',\n",
              " 'Unstable angina is considered an acute coronary syndrome .',\n",
              " 'The 2nd dose of each may be given as soon as 4 wk later in an attempt to induce seroconversion as early as possible , although typically a 3-mo interval between varicella vaccine doses is preferred in noninfected children < 13 yr .',\n",
              " 'Constrictive pericarditis , which is rare , occurs when the fluid that accumulates is thick and fibrous and causes the layers of the pericardium to stick together .',\n",
              " 'The breasts and prostate gland are palpated for masses , and the spleen is palpated for enlargement .',\n",
              " \"This injury is caused by pressure against the nerve due to The way the fetus was positioned in the uterus before birth ; The nerve being pressed against the mother 's pelvis during delivery ; Forceps used to assist the delivery .\",\n",
              " 'If new ones appear too rapidly or to remove , excision of the rectum and permanent ileostomy are needed .',\n",
              " 'Common examples of such causes include the following : A low level of thyroid hormone ( hypothyroidism ) ; Sleep apnea ; Sedation due to an overdose of opioids or alcohol ; Blockage or narrowing of the airways ; Injury to the lungs ; Damage to bones and tissues around the lungs ; Weakness of muscles that normally inflate the lungs .',\n",
              " 'The main symptom of dissociative amnesia is memory loss that is inconsistent with normal forgetfulness .',\n",
              " 'If the appendix ruptures , pain may lessen for several hours .',\n",
              " 'Infants of diabetic mothers have hyperinsulinemia caused by high maternal glucose levels ; they may develop transient hypoglycemia after birth , when maternal glucose is withdrawn .',\n",
              " 'Victims may have tears in their genitals ( such as the vagina ) or anus , cuts and bruises , upsetting emotions , and difficulty sleeping .',\n",
              " 'More specific diagnostic tests ( eg , upper endoscopy , colonoscopy , barium x-rays ) are indicated to diagnose several causes of malabsorption .',\n",
              " 'Surgery .',\n",
              " 'Rarely , central blindness results from infarction in the occipital cortex caused by arterial lesions in the distal cervical region or base of the brain .',\n",
              " 'Why some people become ill so much sooner than others is not fully understood , but a number of genetic factors appear to influence both susceptibility to infection and progression to AIDS after infection .',\n",
              " 'Candidiasis of the esophagus is a defining opportunistic infection in AIDS .',\n",
              " 'Epsilon toxin from C. perfringens is mainly of historical interest as an agent reportedly developed by Iraq in the 1980s .',\n",
              " 'of the lung due to bacteremia or inhalation of contaminated aerosols ( ie , airborne particles containing Legionella species , Aspergillus species , or influenza virus ) are less common causes .',\n",
              " 'Loss of appetite ( anorexia ) eventually occurs in most people who are dying .',\n",
              " 'Thrombocytopenia and decreased production of clotting factors can make clotting unpredictable , increasing risk of both bleeding and thromboembolic disease ( even though INR is usually increased ) .',\n",
              " \"If the diagnosis of a skin abnormality is not clear from its appearance and the person 's history , removal ( biopsy ) of a skin sample may be necessary so that it can be analyzed .\",\n",
              " 'J Urology 92 ( 2 ) , 2014 .',\n",
              " 'occur worldwide .',\n",
              " 'Personality changes and behavioral disturbances may develop early or late .',\n",
              " 'Because of the relationship between disease and anatomy , methods of seeing into the body have become a mainstay in the diagnosis and treatment of disease .',\n",
              " 'Treatment of amblyopia and refractive errors in the first year optimizes vision .',\n",
              " 'The most common clostridial infection is gastroenteritis ( Clostridium perfringens food poisoning ) , a usually mild infection that typically resolves on its own .',\n",
              " 'It is characterized by deep red , painful gingival tissue that bleeds easily .',\n",
              " 'Treatment of the cause pad',\n",
              " 'Surgical correction or balloon angioplasty ( sometimes with stent placement ) .',\n",
              " 'For some people , language problems are the only symptom for 10 or more years .',\n",
              " 'Platelet activation promotes platelet aggregation and fibrinogen binding and requires the platelet glycoprotein IIb/IIIa complex .',\n",
              " 'If the victim chooses to proceed , doctors are required by law to notify the police and to examine the victim .',\n",
              " 'Cyclosporiasis is caused by an obligate intracellular coccidian protozoa .',\n",
              " 'Primary progressive pattern : The disease progresses gradually with no remissions or obvious relapses , although there may be temporary plateaus during which the disease does not progress .',\n",
              " 'The radiation absorbed dose ( rad ) is the amount of that radiation energy absorbed per unit of mass .',\n",
              " 'Some pull out hair from widely scattered areas to disguise the loss .',\n",
              " 'The remaining 87 would have a negative test result .',\n",
              " 'The usual cause is herpesvirus 6 , one of the many human herpesviruses .',\n",
              " 'Beta- thalassemia major ( or Cooley anemia ) occurs in homozygotes ( beta 0 ) or severe compound heterozygotes ( beta + ) and results from severe beta globin deficiency .',\n",
              " 'In some people , the tremor gradually worsens over time , eventually resulting in disability .',\n",
              " 'Paroxysmal atrial tachycardia is uncommon and usually occurs in patients who have had previous episodes of it .',\n",
              " 'Infection is more severe if the fetus is infected early in the pregnancy .',\n",
              " 'It can cause a heterogeneous group of disorders .',\n",
              " 'Migraines often occur less often and become less severe in the last trimester of pregnancy when estrogen levels are relatively stable , and they worsen after childbirth when estrogen levels decrease rapidly .',\n",
              " 'Photographs of the patient are important in delineating the course of the disease .',\n",
              " ', which is produced from polyunsaturated vegetable oils , is usually a healthier substitute for butter , which is high in saturated fat ( about 60 % ) .',\n",
              " 'For either DVT or PE , local ( ie , direct ) administration of thrombolytic therapy with an indwelling catheter ( during percutaneous thrombectomy ) has not been shown to be preferable to IV administration .',\n",
              " 'Their eye movements may be impaired , their facial muscles and the tongue may twitch uncontrollably , and their eyes may bulge .',\n",
              " 'Immunosuppressive therapy and plasma exchange further reduce IgG , increasing platelet counts .',\n",
              " 'Sometimes a limb suddenly swells .',\n",
              " 'Main categories include ; Hematopoietic colony-stimulating factors ( ) ; Interleukins ; Interferons ( IFN - alpha , IFN-beta , IFN -gamma ) ; growth factors ( ) ; Tumor necrosis factors ( TNF-alpha , lymphotoxin -beta ) .',\n",
              " 'Each has a number of smaller areas , each with specific functions .',\n",
              " 'Myelin and axons in the anterior columns are also lost .',\n",
              " 'People with internuclear ophthalmoplegia may have double vision .',\n",
              " 'Lowering serum urate may also decrease the frequency of acute arthritic attacks .',\n",
              " 'Dabigatran and apixaban must be taken twice a day .',\n",
              " 'Women with pelvic muscle hypertonicity , including some with PVD , may benefit from pelvic physical therapy using pelvic floor muscle training , possibly with biofeedback , to teach pelvic muscle relaxation .',\n",
              " \"A doctor 's evaluation pad\",\n",
              " 'Apomorphine 2 to 6 mg sc can be given up to 5 times/ day as needed .',\n",
              " 'When to stop breastfeeding ( wean the infant ) depends on the needs and desires of both mother and baby .',\n",
              " 'This enzyme is a plasma protease that cleaves von Willebrand factor ; deficiency causes thrombotic thrombocytopenic purpura ( TTP ) and decreased ADAMTS13 activity levels may help identify atypical cases of TTP .',\n",
              " 'Stones that do not pass on their own are removed with lithotripsy or an endoscopic technique .',\n",
              " 'Parkinson disease is treated .',\n",
              " 'During the physical examination , doctors check for the presence of fever or a runny nose .',\n",
              " 'Reporting pain is more socially acceptable than reporting anxiety or depression , and appropriate therapy often depends on out these divergent perceptions .',\n",
              " 'To change behavior , people need certain skills , such as Problem solving ; Stress management ; Self-monitoring ; Contingency management ; Stimulus control .',\n",
              " 'Dendritic cells are dedicated antigen-presenting cells present in barrier tissues ( eg , skin , lymph nodes ) .',\n",
              " 'The dried materials stick to the dressing .',\n",
              " 'Obstructive uropathy is structural or functional of normal urine flow , sometimes leading to renal dysfunction ( obstructive nephropathy ) .',\n",
              " 'The child becomes very short of breath and may lose consciousness .',\n",
              " 'Carbamazepine is indicated for focal-onset , generalized-onset tonic-clonic , and mixed seizures but not absence , myoclonic , or atonic seizures .',\n",
              " 'Doctors diagnose peripheral ulcerative keratitis based on the appearance of the cornea in someone who has a connective tissue disorder .',\n",
              " 'A drug-drug interaction may increase or decrease the effects of one or both drugs .',\n",
              " 'Newborns with polycythemia have a reddish complexion and are sluggish .',\n",
              " 'Imaging tests of the liver are not routinely needed for diagnosis .',\n",
              " 'Polio can not be cured , and available antiviral drugs do not affect the course of the disease .',\n",
              " 'In older infants with rickets , sitting and crawling are delayed , as is fontanelle closure ; there is bossing of the skull and costochondral thickening .',\n",
              " 'One common cause , especially in adults , is an abnormal heart rhythm ( arrhythmia ) .',\n",
              " 'So A , O , R , J : An assessment of 18 FDG PET/CT for thoracic screening and risk stratification of pulmonary nodules in multiple endocrine neoplasia type 1 .',\n",
              " 'It is then placed on the joint of a finger to determine whether and how long the person feels the vibration .',\n",
              " 'Risks include inadequate nutrition ( due to decreased intake of whole grains and dairy ) .',\n",
              " 'Blood tests pad',\n",
              " 'Subsequent analyses of FDA and other data have cast doubt on this conclusion ( 1 ) .',\n",
              " 'Sometimes magnetic resonance imaging or computed tomography .',\n",
              " 'Pseudomonas is a common cause of nosocomial UTI , especially in patients who have had urologic manipulation or obstructive uropathy .',\n",
              " 'However , doctors usually do PCI within the first day or two of hospitalization .',\n",
              " 'Clinical evaluation pad',\n",
              " 'For example , patients who refuse care because they can not afford it could be helped to apply for public benefits such as Medicaid or be told that a suitable payment plan could be arranged .',\n",
              " 'In many patients , 6th cranial nerve palsies resolve once the underlying disorder is treated .',\n",
              " 'If a treatment or an invasive diagnostic test is being considered , people should ask about the following : How effective is the treatment or how accurate is the diagnostic test ?',\n",
              " 'Light chains the reabsorptive capacity of the proximal tubule , reach the distal nephron , and combine with filtered proteins and Tamm-Horsfall mucoprotein ( secreted by cells of the thick ascending limb of Henle ) to form obstructive casts .',\n",
              " 'Possible tests include Rapid strep screening ( for children ) ; Throat culture ( for adults ) ; Flexible fiberoptic laryngoscopy ; X-rays of the neck .',\n",
              " 'Others reserve thrombolytic therapy only for patients with massive ( high -risk ) PE .']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3nl6shazt5R",
        "outputId": "1d8870d4-f9bd-4918-e0fb-e89eb79a27ab"
      },
      "source": [
        "rev_output"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"The most common cause of the person 's body and may be used in the child 's body .\",\n",
              " 'The most common cause of the person may be used , and may be used to be used .',\n",
              " 'The following : , and the ( eg , and can be used for the ) .',\n",
              " 'The diagnosis is not by the first or by the first or by the first .',\n",
              " 'The diagnosis , may be done to be done to be done to be done to be done .',\n",
              " \"The diagnosis of the child may be used in the child 's body , but may be used to be used .\",\n",
              " \"The most common cause of a person 's evaluation .\",\n",
              " '( See also Overview of .',\n",
              " 'The diagnosis of the diagnosis of the first disorder is not used to be used to be used to be used to the first .',\n",
              " \"The diagnosis of the diagnosis are not used for the child 's body ( eg , but are not used ) .\",\n",
              " 'The diagnosis , and the first ( eg , and the first ) is not used in the first .',\n",
              " 'The diagnosis can be used to be used for the first with the first disorder .',\n",
              " 'and ( eg , and ) and .',\n",
              " 'The diagnosis of the diagnosis of blood ( eg , and blood ) is not used to check for other drugs .',\n",
              " 'The risk of the diagnosis of the , and can be used in the child with a or a or a .',\n",
              " \"The most common causes of the person 's disorder , but are not used to the person 's evaluation ( eg , but the person 's evaluation ) is not be used to be used to be used to be used to be used to the person 's evaluation .\",\n",
              " \"The diagnosis of the diagnosis of the diagnosis of the diagnosis of the child 's examination is not used .\",\n",
              " 'The most common causes of the person ( eg , and blood ) are not used to check for the first .',\n",
              " 'The diagnosis may be used by the first by the first or by the first .',\n",
              " \"The following , and other drugs , and other drugs , and other drugs , and sometimes in the child 's symptoms .\",\n",
              " 'The diagnosis may be used to be used .',\n",
              " 'The diagnosis are not used in people who are not used to be done .',\n",
              " \"The diagnosis of a person 's evaluation to a person 's evaluation to a person 's evaluation to a person 's evaluation to a person 's evaluation to check for the first .\",\n",
              " 'The diagnosis of other drugs , or an examination , or by an examination , or by an examination , or by the first .',\n",
              " 'The diagnosis of the diagnosis of the first disorder is not used to be used to be used to be used to be used to be used .',\n",
              " 'The most common causes of the risk of blood ( eg , and other drugs ) of the body and other drugs .',\n",
              " 'The diagnosis is not used to be used to be used to be used to determine whether they have an .',\n",
              " '.',\n",
              " ': ; .',\n",
              " 'The diagnosis is not more common of the diagnosis of the first disorder ( for other drugs ) is not used to be used to be used to be used to be used to check for the first .',\n",
              " 'The most common cause of a and a and .',\n",
              " \"The risk of the diagnosis of the diagnosis of the diagnosis of the person 's body ( eg , and the first ) is not used in the first .\",\n",
              " 'The diagnosis of patients with a person with other drugs or with an examination .',\n",
              " \"The diagnosis is a person 's evaluation and is a person 's evaluation of the person 's evaluation .\",\n",
              " \"The diagnosis is a person 's evaluation and is a person 's evaluation of the person 's evaluation .\",\n",
              " \"The risk of the person 's blood ( the person 's blood ) of the person 's evaluation of the person 's evaluation of the person 's evaluation of the person 's evaluation .\",\n",
              " \"The diagnosis may be used to be a person 's evaluation by a person 's evaluation .\",\n",
              " 'The diagnosis of the diagnosis .',\n",
              " \"The diagnosis of a person 's evaluation in a person 's evaluation or a person 's evaluation .\",\n",
              " 'The diagnosis of the diagnosis of the diagnosis of the body and other drugs .',\n",
              " \"The most common cause of the most common cause of the most common cause of the risk of the child 's examination and in the .\",\n",
              " 'The diagnosis are not used for by .',\n",
              " 'The most common cause of the first , and in the first , and are not used in the first .',\n",
              " '.',\n",
              " 'The most common cause of in patients with and .',\n",
              " 'The diagnosis is not used for people with other drugs and other drugs .',\n",
              " 'The diagnosis is not used to be used to be used to be used to be used to be used to be used to be used to check for the child .',\n",
              " \"The diagnosis , can be a person 's evaluation to the first to the child 's examination to the child 's examination is not be used to be used to the child 's evaluation .\",\n",
              " 'The most common cause are not used to help for the first than the first 5 % of patients with the first .',\n",
              " 'The following : , may be used for the ( eg , or by the ) .',\n",
              " \"The most common cause of the child 's examination of the first to the child 's examination of the first .\",\n",
              " \"The diagnosis of the diagnosis of the child 's disorder is not used for the child 's evaluation .\",\n",
              " \"The diagnosis can be used to be used to be used to be used for example , or if they have a person 's evaluation , and other drugs .\",\n",
              " 'The risk of the child can be used to check for the first ( eg , and other drugs ) is not used to check for the first .',\n",
              " 'The most common causes of patients with a , and for patients with .',\n",
              " 'The diagnosis of the diagnosis of the first ; or by the first .',\n",
              " \"The diagnosis of a person may be a person by a person 's evaluation .\",\n",
              " \"The diagnosis of a person 's evaluation ( eg , or a person ) is not used .\",\n",
              " 'The most common cause and the first .',\n",
              " 'The diagnosis of the diagnosis of blood pressure , and blood pressure is not used to be used to be used .',\n",
              " \"The most common cause of the child 's examination in the first .\",\n",
              " 'The most common cause of the first and the first .',\n",
              " \"The diagnosis of a person may be used for a person 's evaluation and may be used for a person 's evaluation .\",\n",
              " \"The diagnosis is not used in the first disorder , and may be used in the child 's evaluation .\",\n",
              " 'The diagnosis of the diagnosis of the diagnosis of ( eg , and ) .',\n",
              " '.',\n",
              " \"The most common of the child of the child with of the child 's examination is not used for the child 's examination .\",\n",
              " \"The diagnosis of a person 's evaluation , and the person 's evaluation of the person 's evaluation ( eg , and the person 's evaluation ) is not used to a person 's evaluation .\",\n",
              " 'The diagnosis of the first to check for patients .',\n",
              " 'The diagnosis is not more likely to have the first than the diagnosis of the diagnosis .',\n",
              " \"The diagnosis , can be done to the child 's examination , or the child 's evaluation .\",\n",
              " 'The diagnosis is by other drugs by or by .',\n",
              " 'The most common causes of the first and for the .',\n",
              " \"The most common cause of the person 's examination , and the first are not used in the first .\",\n",
              " \"The diagnosis of the person are not used to check for the first to check for the child 's disorder ( eg , and may be used for the first .\",\n",
              " 'The diagnosis can be used for with a person with an examination or .',\n",
              " 'The most common cause of the person may be used to the first to the first than the first .',\n",
              " \"The most common cause of the child 's examination and other drugs .\",\n",
              " '( See also Overview of ) .',\n",
              " '.',\n",
              " 'The diagnosis can be used to be used by a person by the first .',\n",
              " 'and .',\n",
              " \"The diagnosis can be done to be done to the person 's .\",\n",
              " 'The diagnosis is not more likely to be done to be done to be done .',\n",
              " \"The diagnosis is not used for patients with other drugs and other drugs for the child 's examination .\",\n",
              " 'The diagnosis of the child , and other drugs are not used for the body , and the first .',\n",
              " 'The most common cause and other drugs to check for the first for the first .',\n",
              " 'The most common cause of the first and can be used in the body ( and can be used in and may be used .',\n",
              " \"The diagnosis is a person 's evaluation .\",\n",
              " 'The diagnosis may be used to be done to be done to be done to be done to be done .',\n",
              " \"The most common causes of the first for the child 's examination of the child 's examination is not used for the child 's examination .\",\n",
              " 'The following : , or ( eg , or ) can be used .',\n",
              " 'The diagnosis of the diagnosis of other drugs or .',\n",
              " 'The diagnosis , or a few % of people .',\n",
              " 'The first examination can be used to check for the first and other drugs .',\n",
              " 'The diagnosis of the child may be used to be used .',\n",
              " \"The diagnosis is not used to be used to be used to be used to be used to be used to the child 's disorder .\",\n",
              " \"The diagnosis of a person with a person with a person with a person 's evaluation with a person 's evaluation .\",\n",
              " 'The most common cause of patients with or .',\n",
              " 'The diagnosis , can be used in the first .',\n",
              " 'The diagnosis is usually used for patients with other drugs is not used for patients with .',\n",
              " \"The diagnosis with the diagnosis should be used for the child 's symptoms and other drugs .\",\n",
              " 'The diagnosis of the diagnosis of the diagnosis of the diagnosis of other drugs .',\n",
              " \"The diagnosis of the diagnosis of the diagnosis of the child with the child 's disorder may be used .\",\n",
              " \"The diagnosis can be used to be done to be done to the child 's disorder ( eg , and the child ) .\",\n",
              " 'The most common cause are not used in the first with the first disorder or in the first .',\n",
              " 'The diagnosis may be used to be done to be done .',\n",
              " 'The diagnosis of .',\n",
              " 'The diagnosis is not more likely to be done to be done to be done to be done to be done to be done to be done .',\n",
              " 'The diagnosis of the diagnosis of the first disorder are not used to check for other drugs .',\n",
              " \"The diagnosis of the diagnosis of the first disorder may be used to check for the child 's examination and may be used for the first .\",\n",
              " 'The most common cause are not used to help to check for the first .',\n",
              " \"The most common cause of the first person 's examination , and other drugs for the child 's examination .\",\n",
              " 'The diagnosis of the first disorder and can be used to help for people .',\n",
              " 'The diagnosis is not used by the first disorder and is not used .',\n",
              " 'The first disorder can be used to the first and can be used .',\n",
              " 'The diagnosis , are not used to the child , but the first , but they are not be used .',\n",
              " 'The diagnosis is not used , but may be done to be done .',\n",
              " 'The most common cause of the first by the first and can be used to be used to the first .',\n",
              " 'The diagnosis is not used to be used to be used to the first .',\n",
              " 'The diagnosis of the diagnosis of the first disorder ( eg , and other drugs ) is not used to check for the first .',\n",
              " 'The diagnosis of the diagnosis of the diagnosis of the diagnosis of the diagnosis of the diagnosis of the diagnosis of the diagnosis .',\n",
              " 'The most common cause of patients with .',\n",
              " 'The diagnosis of other drugs to be used .',\n",
              " \"The diagnosis is not used to be done to be used to be done to the child 's examination ( eg , or the child ) .\",\n",
              " \"The diagnosis is not used to determine whether the person is not used and the person 's body is not done .\",\n",
              " \"The most common causes of the person 's examination of the first ( ) .\",\n",
              " \"The diagnosis of the person is not used for the person 's disorder and may be used .\",\n",
              " \"The most common causes of the person 's examination ; the first are not used to check for the first .\",\n",
              " \"The diagnosis of a person 's evaluation of a person 's evaluation of a person 's evaluation of the child 's evaluation .\",\n",
              " \"The diagnosis may be used to be used , and may be used for the child 's heart , and may be used .\",\n",
              " 'The diagnosis is usually not used in the first , and other drugs , and other drugs .',\n",
              " \"The most common cause of the first to the child 's examination of the child 's examination .\",\n",
              " \"The diagnosis is usually not used in people with a person 's evaluation and other drugs .\",\n",
              " \"The diagnosis of a person is a person 's evaluation of the child 's examination ( eg , or a person 's examination ) .\",\n",
              " \"The diagnosis is not used in patients with other drugs or with a person 's evaluation or in patients with a doctor .\",\n",
              " \"The diagnosis is a person with a person with a person with a person with a person 's evaluation is not used .\",\n",
              " 'The diagnosis of the first disorder is not used to check for the first .',\n",
              " 'The diagnosis is usually not used in patients with other drugs .',\n",
              " \"The diagnosis of the person is not used to be used to the person 's disorder .\",\n",
              " \"The diagnosis , may be used to a person 's evaluation , and may be used to be used to be used to be used to be used to be done .\",\n",
              " \"The most common cause of a person 's evaluation and may be used for the person 's evaluation of the person 's evaluation .\",\n",
              " 'The diagnosis of the first are not used to be used to be used to be used to be used .',\n",
              " \"The diagnosis is a person 's evaluation , and is not used .\",\n",
              " \"The diagnosis of a person 's evaluation to a person 's evaluation to a person 's evaluation to a person 's evaluation to the person 's evaluation .\",\n",
              " \"The most common cause of the person with a person 's evaluation with a person 's evaluation and may be used for the person 's evaluation .\",\n",
              " \"The diagnosis is a person 's evaluation , but is not a person 's evaluation , but is not used to be used to be used .\",\n",
              " \"The diagnosis of a person 's evaluation with a person 's evaluation of the diagnosis of the child 's evaluation of the child 's evaluation .\",\n",
              " \"The most common cause of the first in the child 's examination of the child 's examination of the child 's examination .\",\n",
              " '.',\n",
              " \"The diagnosis is usually used for patients with a person 's examination of the child 's examination is not used for the child 's examination .\",\n",
              " \"The diagnosis of a person may be used in a person 's evaluation or in a person 's evaluation is not used to prevent a person 's evaluation .\",\n",
              " \"The diagnosis is the first common , and is not used to the first the child 's body 's body 's examination is not used to the first .\",\n",
              " 'The most common cause are not used to determine whether the first disorder is not used to check for the first .',\n",
              " \"The diagnosis is not more likely to be used to be used to be done to be used to be done to be done to be done to be done to the person 's to be done to be done to be done .\",\n",
              " \"The doctor 's evaluation with a doctor 's evaluation .\",\n",
              " 'The risk of the risk of the risk of the body ( eg , and other drugs ) ; the body ; .',\n",
              " 'The diagnosis of patients with a person with a person with a person with a person with a person with a person with a person with a .',\n",
              " \"The diagnosis of the child may be used to be used for the child 's examination of the child 's examination .\",\n",
              " 'The diagnosis of the diagnosis of by a person may be used .',\n",
              " \"The diagnosis may be used in the first disorder , and may be used in the child 's evaluation ( eg , and may be used ) .\",\n",
              " \"The most common causes of the person 's disorder , but are not used to check for the first .\",\n",
              " 'The most common cause of patients with , and for patients with .',\n",
              " 'The diagnosis of the diagnosis of the first disorder in the first disorder by the first disorder .',\n",
              " \"The diagnosis is not more likely to have a person 's evaluation to have a person 's evaluation to have a person 's evaluation to be used to be used to be used to be used to be used to be done to be used to be used to be used to be done to be done to have a person 's .\",\n",
              " \"The diagnosis of a person is a person 's evaluation in the person 's evaluation of the person 's evaluation of the person 's heart failure .\",\n",
              " 'The diagnosis of the diagnosis is not used in patients with the first or by the first .',\n",
              " '.',\n",
              " 'The most common causes of ( eg , in patients with ) of the child is not used in patients with .',\n",
              " \"The diagnosis of the diagnosis of the first person 's heart and other drugs ( eg , and can be used to be used to help prevent other drugs ) .\",\n",
              " \"The diagnosis of the person is a person 's evaluation of the person 's evaluation and is not a person 's evaluation ( eg , and may be used to the person 's evaluation ) .\",\n",
              " '( See also Overview of ) .',\n",
              " '.',\n",
              " \"The diagnosis and may be used for a person 's evaluation .\",\n",
              " \"The most common cause of the person 's examination of the first person 's evaluation and the child 's evaluation of the child 's evaluation .\",\n",
              " 'The most common cause of the first in the first and .',\n",
              " \"The diagnosis is a person 's evaluation ( eg , or a person ) is a person 's evaluation is a person 's evaluation .\",\n",
              " 'The diagnosis is by other drugs , by the first , and is not used .',\n",
              " \"The most common cause of the child 's examination of the child 's examination .\",\n",
              " \"The diagnosis of a person with a doctor 's evaluation ( ) .\",\n",
              " 'The diagnosis of the diagnosis are not used for the child for the child .',\n",
              " \"The most common cause and the first person 's and sometimes and other drugs .\",\n",
              " 'The most common cause of the first , and are not used to the first .',\n",
              " 'The diagnosis is by a by or by .',\n",
              " \"The following : or a or a person 's evaluation with the child 's evaluation , may be used for the child 's evaluation with the child 's examination .\",\n",
              " \"The diagnosis of the person is not used for the person 's disorder of the person 's evaluation ( eg , or to the person 's evaluation ) .\",\n",
              " 'The diagnosis of the diagnosis of the first disorder is not used to be used .',\n",
              " \"The diagnosis of a person 's evaluation or a person 's evaluation .\",\n",
              " \"The diagnosis is not used to be used to be used to the child 's child 's examination of the child 's examination .\",\n",
              " \"The diagnosis of a person ( eg , and other drugs ) is not used in with a person 's evaluation .\",\n",
              " \"The diagnosis of the child , usually in the first , or in the child 's examination .\",\n",
              " 'The diagnosis is not used in people with other drugs and other drugs .',\n",
              " \"The diagnosis is the person 's disorder in the person is not used .\",\n",
              " \"The diagnosis of a person can be a person 's evaluation of a person 's evaluation .\",\n",
              " 'The most common cause of the first and are not used in the first to check for the first 5 % of the first 5 % of the first .',\n",
              " \"The most common cause of the person 's body of the body in the body of the body of the child 's body .\",\n",
              " '.',\n",
              " 'The diagnosis of other drugs ( eg , by an examination ) can be used to be used .',\n",
              " 'The most common cause , and may be used to the first , and may be used .',\n",
              " 'The most common cause and other drugs , and other drugs , and other drugs .',\n",
              " 'The most common cause of a and for a for a .',\n",
              " '.',\n",
              " \"The diagnosis of a person 's evaluation , or .\",\n",
              " \"The most common cause and the person 's body in the first .\",\n",
              " 'The diagnosis of patients with a or .',\n",
              " \"The diagnosis of the person may be used to be used to the person 's disorder .\",\n",
              " 'The most common cause of a and for a for a .',\n",
              " 'The diagnosis of other drugs , or by an examination , or by a few % of patients with an examination , or , or .',\n",
              " 'The most common cause of the child with and .',\n",
              " 'The diagnosis can be done to be done to be done to be done to be done .',\n",
              " 'The most common cause of the first and the first ( eg , and the first ) is not used to the first .',\n",
              " \"The diagnosis is a person 's evaluation and a person 's evaluation ( eg , and is a person 's evaluation ) is a person 's evaluation and may be used .\",\n",
              " \"The diagnosis of other drugs are not used for patients with a person with a person 's evaluation .\",\n",
              " 'The diagnosis is not used for patients with other drugs .',\n",
              " \"The diagnosis of the child 's examination of the child 's examination of the child 's examination is not used .\",\n",
              " 'The diagnosis is not used to have a person with other drugs , and other drugs .',\n",
              " ', ; , .',\n",
              " 'The most common cause are not used in patients who are not used in the child ( eg , in the child ) .',\n",
              " 'The most common cause of the first to the first the first .',\n",
              " \"The diagnosis is not a doctor 's evaluation with a doctor .\",\n",
              " \"The most common cause of the first and may be used for the child 's examination .\",\n",
              " 'The diagnosis is not used , and other drugs , and other drugs , and other drugs .',\n",
              " \"The diagnosis of the child 's examination is not a person 's evaluation of the child 's evaluation .\",\n",
              " \"The diagnosis of the diagnosis of the person may be used for the child 's disorder .\",\n",
              " \"The most common cause and a person 's evaluation .\",\n",
              " 'The diagnosis of the diagnosis of the diagnosis of the diagnosis of the person .',\n",
              " \"The first , and can be used to be used to the child 's first to the first .\",\n",
              " \"The diagnosis of the diagnosis are not used for the child with the child 's body or .\",\n",
              " 'The most common cause is usually used in patients with a , and in patients with ( eg , in patients with ) .',\n",
              " ', .',\n",
              " \"The diagnosis is a person 's evaluation and the person 's evaluation to the person 's evaluation .\",\n",
              " \"The most common cause of the first person 's evaluation ( and other drugs ) .\",\n",
              " 'The most common cause of patients with and for patients with .',\n",
              " \"The diagnosis of the diagnosis of blood ( eg , and blood ) of the child 's evaluation .\",\n",
              " 'The diagnosis can be used for patients with a or with a or .',\n",
              " \"The diagnosis is a person 's evaluation , but is not used in people who have a person 's evaluation , or in a person 's evaluation .\",\n",
              " \"The diagnosis , can be used for the child of the child 's examination .\",\n",
              " \"The diagnosis of the diagnosis of the child 's evaluation is not used .\",\n",
              " 'The diagnosis can be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used .',\n",
              " \"The diagnosis of the child is not used to determine whether the child 's disorder is not used to check for the child 's disorder .\",\n",
              " \"The diagnosis is a person 's evaluation of the person is not used for the person 's disorder is not used for the person 's evaluation .\",\n",
              " '.',\n",
              " 'The most common causes of the following : ( eg , ) ; .',\n",
              " 'The diagnosis of patients with a person with a person with or ( eg , with ) .']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_JjNm4y86Zk"
      },
      "source": [
        "#Save results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCUZbQUX88Pi"
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/gold_test_trial1.txt\", \"w\") as output:\n",
        "  for line in gold_text:\n",
        "    output.write(line + '\\n')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_czyMnfT9HVW"
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/raw_output_trial1.txt\", \"w\") as output:\n",
        "  for line in raw_output:\n",
        "    output.write(line + '\\n')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTTsef9A9Hp9"
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/rev_output_trial1.txt\", \"w\") as output:\n",
        "  for line in rev_output:\n",
        "    output.write(line + '\\n')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfKuzfZ3-4c3"
      },
      "source": [
        "#Evaluation BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knw-mQI03sK7"
      },
      "source": [
        "  \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Aq0p-C3u-B",
        "outputId": "a194cce5-4422-43ad-dee7-98efbf2499da"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wDm8QTquAqk"
      },
      "source": [
        "def nltk_bleu(texts_origin, text_transfered):\n",
        "  texts_origin = [word_tokenize(text_origin.lower().strip()) for text_origin in texts_origin]\n",
        "  text_transfered = word_tokenize(text_transfered.lower().strip())\n",
        "  return sentence_bleu(texts_origin, text_transfered) * 100"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcg63sP43bCk",
        "outputId": "5d91229b-2aec-46ff-8604-766ddf88c8a2"
      },
      "source": [
        "bleu_scores_raw = []\n",
        "bleu_scores_rev = []\n",
        "for i in range(len(gold_text)):\n",
        "  bleu_scores_raw.append(nltk_bleu(gold_text[i],raw_output[i]))\n",
        "  bleu_scores_rev.append(nltk_bleu(gold_text[i],rev_output[i]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcz70Nel_j8r",
        "outputId": "be27e5c7-3183-438e-94c9-1a8882731e47"
      },
      "source": [
        "\n",
        "import statistics\n",
        "statistics.mean(bleu_scores_raw)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57.07954434495195"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBMLlyBzAQqN",
        "outputId": "20685482-8528-4768-9450-6494e81a91b7"
      },
      "source": [
        "\n",
        "import statistics\n",
        "statistics.mean(bleu_scores_rev)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56.821192493168574"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcTdr_ZXAVIj"
      },
      "source": [
        "#Save BLEUS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzGhE_GZAWgY"
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/bleus_rev.txt\", \"w\") as output:\n",
        "  for line in bleu_scores_rev:\n",
        "    output.write(str(line) + '\\n')\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/style_transfer/training_files/bleus_raw.txt\", \"w\") as output:\n",
        "  for line in bleu_scores_raw:\n",
        "    output.write(str(line) + '\\n')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmHb_9Shv6qx",
        "outputId": "be7325dd-9ab9-4b00-a8c7-4221cfb7be75"
      },
      "source": [
        "# n-gram individual BLEU\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "#reference = [['this', 'is', 'a', 'test']]\n",
        "#candidate = ['this', 'is', 'a', 'test']\n",
        "#print('Individual 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
        "#print('Individual 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 1, 0, 0)))\n",
        "#print('Individual 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 1, 0)))\n",
        "print('Individual 4-gram: %f' % sentence_bleu(gold_text[10], raw_output[10], weights=(0, 0, 0, 1)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual 4-gram: 1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpKJhSHuwUjT"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNYoiF6wwLH4",
        "outputId": "3f4e256d-3b5e-4c0c-9d69-514f1a6d2c7f"
      },
      "source": [
        " with torch.no_grad():\n",
        "  raw_log_probs = model_F(\n",
        "      inp_tokens,\n",
        "      None,\n",
        "      inp_lengths,\n",
        "      raw_styles,\n",
        "      generate=True,\n",
        "      differentiable_decode=False,\n",
        "      temperature=1,\n",
        "  )\n",
        "            \n",
        "with torch.no_grad():\n",
        "    rev_log_probs = model_F(\n",
        "        inp_tokens, \n",
        "        None,\n",
        "        inp_lengths,\n",
        "        rev_styles,\n",
        "        generate=True,\n",
        "        differentiable_decode=False,\n",
        "        temperature=1,\n",
        "    )\n",
        "                \n",
        "gold_text += tensor2text(vocab, inp_tokens.cpu())\n",
        "raw_output += tensor2text(vocab, raw_log_probs.argmax(-1).cpu())\n",
        "rev_output += tensor2text(vocab, rev_log_probs.argmax(-1).cpu())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the length of max_enc_len is 29\n",
            "the length of max_enc_len is 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb66p_k-wbSk",
        "outputId": "f62c072d-87fc-404d-87e1-ed7cf697c089"
      },
      "source": [
        "gold_text"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Variable numbers of immature white blood cells and platelets also may be present in the blood .',\n",
              " 'Blunt trauma may cause ecchymosis ( eg , the transverse , linear ecchymosis termed seat belt sign ) , but this finding has poor sensitivity and specificity .']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rl5i_YAOK4z",
        "outputId": "9e3920b6-a8da-48b9-fe55-5b0e3a9e7f9d"
      },
      "source": [
        "inp_styles"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV77DBm-MLaf"
      },
      "source": [
        "rev_styles = 1 - inp_styles"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdPHxaFyOON5",
        "outputId": "f59b0b29-5d3c-489d-e31e-c7a63c96402d"
      },
      "source": [
        "rev_styles"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4M_xT3uKn4k",
        "outputId": "e3ea612d-c92b-407c-ee73-82f9b38470f2"
      },
      "source": [
        "inp_tokens"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  95,    3,  100,   51,   81,   26, 3792,    5,   87, 2740,  142, 3458,\n",
              "            4,    2, 5912, 5912, 5912, 5912, 5912],\n",
              "        [3466, 1581,   22, 4343,   44,   13,  552,  127,   14,   34,   17,   13,\n",
              "          118,  134,   15,   38, 1100,    4,    2]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l83yHU9KPHBl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpAUS_nVLjlx"
      },
      "source": [
        "raw_output = tensor2text(vocab, raw_gen_log_probs.argmax(-1).cpu())"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLO8JUJ5Ltyd",
        "outputId": "4460d1df-d4f1-4877-a04c-348e0473f703"
      },
      "source": [
        "raw_output"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The of in the disorder and the and in the body .',\n",
              " 'The of the are of a of the disease of the is .']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9UHBqgdNCb7"
      },
      "source": [
        "rev_output = tensor2text(vocab, rev_gen_log_probs.argmax(-1).cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66TEBIcHJo45"
      },
      "source": [
        "#Cache clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1SOp2bD7v2N"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivPyzzXN7v5o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "4ebe074f-a19d-4b5e-e8ef-b38b36d15b10"
      },
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   14822 MB |   14822 MB |    1665 GB |    1650 GB |\\n|       from large pool |   12145 MB |   12145 MB |    1582 GB |    1570 GB |\\n|       from small pool |    2677 MB |    2679 MB |      82 GB |      80 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   14822 MB |   14822 MB |    1665 GB |    1650 GB |\\n|       from large pool |   12145 MB |   12145 MB |    1582 GB |    1570 GB |\\n|       from small pool |    2677 MB |    2679 MB |      82 GB |      80 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   15330 MB |   15330 MB |   15330 MB |       0 B  |\\n|       from large pool |   12642 MB |   12642 MB |   12642 MB |       0 B  |\\n|       from small pool |    2688 MB |    2688 MB |    2688 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  519745 KB |    1226 MB |    1933 GB |    1932 GB |\\n|       from large pool |  508816 KB |    1220 MB |    1844 GB |    1843 GB |\\n|       from small pool |   10929 KB |      86 MB |      88 GB |      88 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |   23950    |   23952    |    1431 K  |    1407 K  |\\n|       from large pool |    4565    |    4565    |     428 K  |     423 K  |\\n|       from small pool |   19385    |   19387    |    1002 K  |     983 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |   23950    |   23952    |    1431 K  |    1407 K  |\\n|       from large pool |    4565    |    4565    |     428 K  |     423 K  |\\n|       from small pool |   19385    |   19387    |    1002 K  |     983 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |    1654    |    1654    |    1654    |       0    |\\n|       from large pool |     310    |     310    |     310    |       0    |\\n|       from small pool |    1344    |    1344    |    1344    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |    1947    |    1948    |  246520    |  244573    |\\n|       from large pool |     269    |     270    |  169601    |  169332    |\\n|       from small pool |    1678    |    1678    |   76919    |   75241    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8CplgUNBMQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}